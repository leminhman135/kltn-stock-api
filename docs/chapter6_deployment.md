# CH∆Ø∆†NG 6: TRI·ªÇN KHAI H·ªÜ TH·ªêNG, TH·ª∞C NGHI·ªÜM V√Ä ƒê√ÅNH GI√Å

## 6.1. M√¥i Tr∆∞·ªùng Th·ª±c Nghi·ªám V√† D·ªØ Li·ªáu S·ª≠ D·ª•ng

### 6.1.1. C·∫•u h√¨nh ph·∫ßn c·ª©ng

H·ªá th·ªëng ƒë∆∞·ª£c ph√°t tri·ªÉn v√† th·ª≠ nghi·ªám tr√™n hai m√¥i tr∆∞·ªùng:

**M√¥i tr∆∞·ªùng ph√°t tri·ªÉn (Local Development):**

| Th√†nh ph·∫ßn | C·∫•u h√¨nh |
|------------|----------|
| CPU | Intel Core i5/i7 ho·∫∑c AMD Ryzen 5/7 |
| RAM | 16GB DDR4 |
| ·ªî c·ª©ng | SSD 256GB tr·ªü l√™n |
| GPU | Kh√¥ng b·∫Øt bu·ªôc (s·ª≠ d·ª•ng CPU cho inference) |
| H·ªá ƒëi·ªÅu h√†nh | Windows 10/11 64-bit |

**M√¥i tr∆∞·ªùng tri·ªÉn khai (Railway Cloud):**

| Th√†nh ph·∫ßn | C·∫•u h√¨nh |
|------------|----------|
| Platform | Railway.app |
| CPU | Shared vCPU |
| RAM | 512MB - 8GB (auto-scale) |
| Database | PostgreSQL (Railway managed) |
| Region | US-West |

### 6.1.2. M√¥i tr∆∞·ªùng ph·∫ßn m·ªÅm v√† virtualenv (venv)

**Phi√™n b·∫£n ph·∫ßn m·ªÅm:**
- H·ªá ƒëi·ªÅu h√†nh: Windows 10/11 (development), Linux (production)
- Python: 3.13.9
- Package Manager: pip 24.x

**T·∫°o v√† k√≠ch ho·∫°t m√¥i tr∆∞·ªùng ·∫£o:**

```bash
# T·∫°o virtual environment
python -m venv venv

# K√≠ch ho·∫°t (Windows)
.\venv\Scripts\activate

# K√≠ch ho·∫°t (Linux/Mac)
source venv/bin/activate

# C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt
```

**C√°c nh√≥m th∆∞ vi·ªán ch√≠nh (tr√≠ch t·ª´ `requirements.txt`):**

```python
# API Core - KLTN Stock Prediction v2.1
fastapi==0.117.1
uvicorn[standard]==0.38.0
pydantic==2.12.5

# Database
sqlalchemy==2.0.44
psycopg2-binary==2.9.11
alembic==1.17.2

# X·ª≠ l√Ω d·ªØ li·ªáu
pandas==2.3.3
numpy==2.3.5

# Machine Learning
scikit-learn==1.6.1
statsmodels>=0.14.0
xgboost>=2.0.0

# Deep Learning (CPU-optimized)
tensorflow-cpu>=2.15.0

# NLP & Sentiment Analysis (FinBERT/PhoBERT)
transformers>=4.36.0
torch>=2.1.0
sentencepiece>=0.1.99

# Technical Analysis
ta>=0.11.0

# Time Series Forecasting
prophet>=1.1.5

# Web Scraping
requests==2.32.5
beautifulsoup4==4.14.2

# Utilities
python-dotenv==1.2.1
joblib>=1.3.0
```

**Ghi ch√∫:** To√†n b·ªô h·ªá th·ªëng ƒë∆∞·ª£c tri·ªÉn khai trong m√¥i tr∆∞·ªùng venv, kh√¥ng s·ª≠ d·ª•ng n8n hay b·∫•t k·ª≥ workflow automation tool n√†o. Pipeline ƒë∆∞·ª£c th·ª±c hi·ªán th√¥ng qua c√°c script Python v√† FastAPI endpoints.

### 6.1.3. M√¥ t·∫£ t·∫≠p d·ªØ li·ªáu d√πng trong th·ª±c nghi·ªám

**D·ªØ li·ªáu gi√° c·ªï phi·∫øu:**

| Th√¥ng tin | Chi ti·∫øt |
|-----------|----------|
| Kho·∫£ng th·ªùi gian | 2020 - 2024 (5 nƒÉm) |
| S·ªë m√£ c·ªï phi·∫øu | 30 m√£ (nh√≥m VN30) |
| Ti√™u ch√≠ ch·ªçn m√£ | Thanh kho·∫£n cao, v·ªën h√≥a l·ªõn |
| Ngu·ªìn d·ªØ li·ªáu | VNDirect API |
| T·∫ßn su·∫•t | Daily OHLCV |

**Danh s√°ch m√£ VN30 ƒë∆∞·ª£c s·ª≠ d·ª•ng (tr√≠ch t·ª´ `src/api_v2.py`):**

```python
VN30_STOCKS = [
    {"symbol": "VNM", "name": "C√¥ng ty C·ªï ph·∫ßn S·ªØa Vi·ªát Nam", "sector": "Consumer Goods"},
    {"symbol": "VIC", "name": "T·∫≠p ƒëo√†n Vingroup", "sector": "Real Estate"},
    {"symbol": "VHM", "name": "Vinhomes", "sector": "Real Estate"},
    {"symbol": "VCB", "name": "Ng√¢n h√†ng TMCP Ngo·∫°i th∆∞∆°ng", "sector": "Banking"},
    {"symbol": "FPT", "name": "FPT Corporation", "sector": "Technology"},
    {"symbol": "HPG", "name": "T·∫≠p ƒëo√†n H√≤a Ph√°t", "sector": "Steel"},
    {"symbol": "MWG", "name": "Th·∫ø Gi·ªõi Di ƒê·ªông", "sector": "Retail"},
    {"symbol": "TCB", "name": "Techcombank", "sector": "Banking"},
    # ... v√† 22 m√£ kh√°c
]
```

**D·ªØ li·ªáu tin t·ª©c:**

| Th√¥ng tin | Chi ti·∫øt |
|-----------|----------|
| Ngu·ªìn tin | CafeF, VnExpress, VietStock, NDH |
| Ph∆∞∆°ng th·ª©c thu th·∫≠p | RSS Feeds + Web Scraping |
| S·ªë b√†i vi·∫øt/ng√†y | ~50-100 b√†i |
| Ng√¥n ng·ªØ | Ti·∫øng Vi·ªát |

**Th·ªëng k√™ c∆° b·∫£n:**

| Lo·∫°i d·ªØ li·ªáu | S·ªë l∆∞·ª£ng |
|--------------|----------|
| S·ªë d√≤ng d·ªØ li·ªáu gi√° | ~37,500 records (30 m√£ √ó 250 ng√†y √ó 5 nƒÉm) |
| S·ªë b√†i b√°o thu th·∫≠p | ~15,000 b√†i |
| S·ªë b·∫£n ghi technical indicators | ~37,500 records |
| S·ªë b·∫£n ghi sentiment | ~15,000 records |

## 6.2. Tri·ªÉn Khai H·ªá Th·ªëng Trong M√¥i Tr∆∞·ªùng venv

### 6.2.1. T·ªï ch·ª©c m√£ ngu·ªìn v√† c·∫•u tr√∫c th∆∞ m·ª•c

C·∫•u tr√∫c project ƒë∆∞·ª£c t·ªï ch·ª©c nh∆∞ sau:

```
KLTN/
‚îú‚îÄ‚îÄ data/                     # D·ªØ li·ªáu th√¥ v√† ƒë√£ x·ª≠ l√Ω
‚îÇ   ‚îî‚îÄ‚îÄ raw_data.csv
‚îú‚îÄ‚îÄ src/                      # Source code ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ api/                  # API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ml_endpoints.py   # ML model endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ advanced_ml_endpoints.py  # FinBERT, LSTM endpoints
‚îÇ   ‚îú‚îÄ‚îÄ backtest/             # Backtesting engine
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ backtesting_engine.py
‚îÇ   ‚îú‚îÄ‚îÄ database/             # Database models v√† connection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connection.py     # SQLAlchemy connection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py         # ORM models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extended_models.py
‚îÇ   ‚îú‚îÄ‚îÄ data_collection/      # Thu th·∫≠p d·ªØ li·ªáu
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trading_data.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ market_data.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ financial_data.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ industry_data.py
‚îÇ   ‚îú‚îÄ‚îÄ etl/                  # ETL Pipeline
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ etl_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ features/             # Feature engineering
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ technical_indicators.py
‚îÇ   ‚îú‚îÄ‚îÄ models/               # ML/DL models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ deep_learning.py  # LSTM, GRU, CNN-LSTM
‚îÇ   ‚îú‚îÄ‚îÄ sentiment/            # Sentiment analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ finbert_analyzer.py
‚îÇ   ‚îú‚îÄ‚îÄ scheduler/            # Task scheduling
‚îÇ   ‚îú‚îÄ‚îÄ static/               # Web dashboard
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ api_v2.py             # Main FastAPI app
‚îÇ   ‚îú‚îÄ‚îÄ model.py              # Ensemble prediction
‚îÇ   ‚îú‚îÄ‚îÄ news_service.py       # News scraping
‚îÇ   ‚îî‚îÄ‚îÄ data_collection.py    # Data collection utilities
‚îú‚îÄ‚îÄ scripts/                  # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ analyze_news_finbert.py
‚îÇ   ‚îú‚îÄ‚îÄ fetch_and_import_data.py
‚îÇ   ‚îî‚îÄ‚îÄ train_models_offline.py
‚îú‚îÄ‚îÄ models/                   # Saved model files
‚îú‚îÄ‚îÄ tests/                    # Unit tests
‚îú‚îÄ‚îÄ requirements.txt          # Dependencies
‚îú‚îÄ‚îÄ Procfile                  # Railway deployment
‚îú‚îÄ‚îÄ railway.json              # Railway config
‚îî‚îÄ‚îÄ main.py                   # Entry point
```

**C√°ch t√°ch module:**

1. **Thu th·∫≠p d·ªØ li·ªáu:** `src/data_collection/`, `src/data_collection.py`
2. **Ti·ªÅn x·ª≠ l√Ω:** `src/etl/etl_pipeline.py`
3. **Ch·ªâ b√°o k·ªπ thu·∫≠t:** `src/features/technical_indicators.py`
4. **Ph√¢n t√≠ch c·∫£m x√∫c:** `src/sentiment/finbert_analyzer.py`
5. **M√¥ h√¨nh chu·ªói th·ªùi gian:** `src/model.py`, `src/models/deep_learning.py`
6. **Ensemble:** `src/model.py` (class `StockMLModel`)
7. **Backtesting:** `src/backtest/backtesting_engine.py`
8. **Dashboard:** `src/static/index.html`, `src/api_v2.py`

### 6.2.2. Thi·∫øt l·∫≠p v√† qu·∫£n l√Ω m√¥i tr∆∞·ªùng venv

**C√°c b∆∞·ªõc th·ª±c hi·ªán:**

```bash
# B∆∞·ªõc 1: Clone repository
git clone https://github.com/leminhman135/kltn-stock-api.git
cd kltn-stock-api

# B∆∞·ªõc 2: T·∫°o virtual environment
python -m venv venv

# B∆∞·ªõc 3: K√≠ch ho·∫°t venv
# Windows:
.\venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# B∆∞·ªõc 4: C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt

# B∆∞·ªõc 5: C·∫•u h√¨nh environment variables
cp scripts/.env.example scripts/.env
# Ch·ªânh s·ª≠a DATABASE_URL trong .env

# B∆∞·ªõc 6: Kh·ªüi ƒë·ªông server
python main.py
# Ho·∫∑c: uvicorn src.api_v2:app --reload
```

**L∆∞u tr·ªØ v√† chia s·∫ª requirements.txt:**

```bash
# Export dependencies hi·ªán t·∫°i
pip freeze > requirements.txt

# C√†i ƒë·∫∑t t·ª´ requirements.txt tr√™n m√°y kh√°c
pip install -r requirements.txt
```

### 6.2.3. C√°c script ch√≠nh v√† lu·ªìng ch·∫°y pipeline

**Danh s√°ch scripts (trong th∆∞ m·ª•c `scripts/`):**

| Script | Ch·ª©c nƒÉng |
|--------|-----------|
| `fetch_and_import_data.py` | Thu th·∫≠p d·ªØ li·ªáu gi√° t·ª´ VNDirect API |
| `analyze_news_finbert.py` | Ph√¢n t√≠ch sentiment tin t·ª©c b·∫±ng PhoBERT |
| `train_models_offline.py` | Hu·∫•n luy·ªán ARIMA, Prophet, LSTM offline |
| `migrate_to_postgres.py` | Migration d·ªØ li·ªáu sang PostgreSQL |

**Lu·ªìng ch·∫°y pipeline:**

```bash
# 1. Thu th·∫≠p d·ªØ li·ªáu gi√°
python scripts/fetch_and_import_data.py --symbols VNM FPT VCB --days 365

# 2. Thu th·∫≠p v√† ph√¢n t√≠ch tin t·ª©c
python scripts/analyze_news_finbert.py --symbols VNM FPT --days 7

# 3. Train models (offline)
python scripts/train_models_offline.py --symbol VNM

# 4. Ch·∫°y API server
python main.py
```

**Ho·∫∑c s·ª≠ d·ª•ng API endpoints:**

```bash
# Sync d·ªØ li·ªáu m·ªõi nh·∫•t
curl -X POST "http://localhost:8000/api/data/sync-daily"

# Ch·∫°y prediction
curl -X POST "http://localhost:8000/api/predictions/predict" \
  -H "Content-Type: application/json" \
  -d '{"symbol": "VNM", "periods": 7}'
```

## 6.3. Tri·ªÉn Khai C√°c M√¥-ƒëun X·ª≠ L√Ω D·ªØ Li·ªáu

### 6.3.1. Thu th·∫≠p v√† c·∫≠p nh·∫≠t d·ªØ li·ªáu gi√°

**Class VNDirectAPI (tr√≠ch t·ª´ `src/data_collection.py`):**

```python
class VNDirectAPI:
    """Thu th·∫≠p d·ªØ li·ªáu t·ª´ VNDirect"""
    
    BASE_URL = "https://finfo-api.vndirect.com.vn/v4/stock_prices"
    
    def get_stock_price(self, symbol: str, from_date: str, 
                        to_date: str) -> pd.DataFrame:
        """
        L·∫•y d·ªØ li·ªáu gi√° c·ªï phi·∫øu t·ª´ VNDirect API
        
        Args:
            symbol: M√£ c·ªï phi·∫øu (VNM, FPT, etc.)
            from_date: Ng√†y b·∫Øt ƒë·∫ßu (YYYY-MM-DD)
            to_date: Ng√†y k·∫øt th√∫c (YYYY-MM-DD)
        
        Returns:
            DataFrame v·ªõi c√°c c·ªôt: date, Open, High, Low, Close, Volume
        """
        params = {
            'sort': 'date',
            'size': 9999,
            'page': 1,
            'q': f'code:{symbol}~date:gte:{from_date}~date:lte:{to_date}'
        }
        
        response = self.session.get(self.BASE_URL, params=params)
        data = response.json()
        
        # Parse v√† return DataFrame
        ...
```

**C∆° ch·∫ø x·ª≠ l√Ω l·ªói v√† logging:**

```python
try:
    df = vndirect.get_stock_price(symbol, from_date, to_date)
    if df.empty:
        logger.warning(f"No data returned for {symbol}")
        return pd.DataFrame()
except requests.exceptions.RequestException as e:
    logger.error(f"API Error for {symbol}: {str(e)}")
    return pd.DataFrame()
except Exception as e:
    logger.error(f"Unexpected error: {str(e)}")
    return pd.DataFrame()
```

### 6.3.2. Thu th·∫≠p v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu tin t·ª©c

**Class NewsService (tr√≠ch t·ª´ `src/news_service.py`):**

```python
class RSSNewsCollector:
    """Thu th·∫≠p tin t·ª©c t·ª´ RSS feeds"""
    
    RSS_SOURCES = {
        'cafef': 'https://cafef.vn/rss/chung-khoan.rss',
        'vnexpress': 'https://vnexpress.net/rss/kinh-doanh.rss',
        'vietstock': 'https://vietstock.vn/rss/chung-khoan.rss',
    }
    
    def fetch_news(self, symbol: str = None, limit: int = 50) -> List[NewsArticle]:
        """
        Thu th·∫≠p tin t·ª©c m·ªõi nh·∫•t
        
        Args:
            symbol: M√£ c·ªï phi·∫øu (optional - l·ªçc theo m√£)
            limit: S·ªë tin t·ªëi ƒëa
        """
        articles = []
        for source, url in self.RSS_SOURCES.items():
            feed = feedparser.parse(url)
            for entry in feed.entries[:limit]:
                article = NewsArticle(
                    title=self._clean_text(entry.title),
                    summary=self._clean_text(entry.get('summary', '')),
                    url=entry.link,
                    source=source,
                    published_at=self._parse_date(entry.published)
                )
                
                # L·ªçc theo symbol n·∫øu c√≥
                if symbol is None or self._match_symbol(article, symbol):
                    articles.append(article)
        
        return articles
```

**Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n:**

```python
def _clean_text(self, text: str) -> str:
    """L√†m s·∫°ch vƒÉn b·∫£n tin t·ª©c"""
    if not text:
        return ""
    
    # B·ªè HTML tags
    text = re.sub(r'<[^>]+>', '', text)
    
    # B·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
    text = re.sub(r'[^\w\s\.,;:!?\-()]', '', text)
    
    # Chu·∫©n h√≥a Unicode (NFC)
    text = unicodedata.normalize('NFC', text)
    
    # B·ªè kho·∫£ng tr·∫Øng th·ª´a
    text = ' '.join(text.split())
    
    return text.strip()
```

### 6.3.3. X√¢y d·ª±ng ƒë·∫∑c tr∆∞ng k·ªπ thu·∫≠t t·ª´ d·ªØ li·ªáu gi√°

**Class TechnicalIndicators (tr√≠ch t·ª´ `src/features/technical_indicators.py`):**

```python
class TechnicalIndicators:
    """T√≠nh to√°n c√°c ch·ªâ b√°o k·ªπ thu·∫≠t ph·ªï bi·∫øn"""
    
    @staticmethod
    def calculate_sma(df: pd.DataFrame, column: str = 'close', 
                      window: int = 20) -> pd.Series:
        """Simple Moving Average (SMA)"""
        return df[column].rolling(window=window).mean()
    
    @staticmethod
    def calculate_ema(df: pd.DataFrame, column: str = 'close', 
                      window: int = 20) -> pd.Series:
        """Exponential Moving Average (EMA)"""
        return df[column].ewm(span=window, adjust=False).mean()
    
    @staticmethod
    def calculate_rsi(df: pd.DataFrame, column: str = 'close', 
                     window: int = 14) -> pd.Series:
        """
        Relative Strength Index (RSI)
        RSI > 70: overbought, RSI < 30: oversold
        """
        delta = df[column].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    
    @staticmethod
    def calculate_macd(df: pd.DataFrame, fast: int = 12, 
                      slow: int = 26, signal: int = 9) -> pd.DataFrame:
        """Moving Average Convergence Divergence (MACD)"""
        ema_fast = df['close'].ewm(span=fast, adjust=False).mean()
        ema_slow = df['close'].ewm(span=slow, adjust=False).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal, adjust=False).mean()
        macd_histogram = macd - macd_signal
        
        return pd.DataFrame({
            'macd': macd,
            'macd_signal': macd_signal,
            'macd_histogram': macd_histogram
        })
    
    @staticmethod
    def calculate_bollinger_bands(df: pd.DataFrame, window: int = 20, 
                                 num_std: float = 2) -> pd.DataFrame:
        """Bollinger Bands"""
        sma = df['close'].rolling(window=window).mean()
        std = df['close'].rolling(window=window).std()
        
        return pd.DataFrame({
            'bb_middle': sma,
            'bb_upper': sma + (std * num_std),
            'bb_lower': sma - (std * num_std)
        })
```

**L∆∞u tr·ªØ v√†o database (SQLAlchemy model):**

```python
class TechnicalIndicator(Base):
    """Technical indicators calculated from price data"""
    __tablename__ = "technical_indicators"
    
    id = Column(Integer, primary_key=True, index=True)
    stock_id = Column(Integer, ForeignKey("stocks.id"), nullable=False)
    date = Column(Date, nullable=False, index=True)
    
    # Moving Averages
    sma_20 = Column(Float)
    sma_50 = Column(Float)
    ema_12 = Column(Float)
    ema_26 = Column(Float)
    
    # Momentum Indicators
    rsi_14 = Column(Float)
    macd = Column(Float)
    macd_signal = Column(Float)
    macd_histogram = Column(Float)
    
    # Volatility Indicators
    bb_upper = Column(Float)
    bb_middle = Column(Float)
    bb_lower = Column(Float)
    atr_14 = Column(Float)
```

### 6.3.4. G·ªôp d·ªØ li·ªáu ƒëa ngu·ªìn

**G·∫Øn tin t·ª©c v·ªõi m√£ c·ªï phi·∫øu:**

```python
def _match_symbol(self, article: NewsArticle, symbol: str) -> bool:
    """Ki·ªÉm tra tin t·ª©c c√≥ li√™n quan ƒë·∫øn m√£ c·ªï phi·∫øu kh√¥ng"""
    text = f"{article.title} {article.summary}".upper()
    
    # T√¨m m√£ tr·ª±c ti·∫øp
    if symbol.upper() in text:
        return True
    
    # T√¨m theo t√™n c√¥ng ty
    company_names = {
        'VNM': ['VINAMILK', 'S·ªÆA VI·ªÜT NAM'],
        'FPT': ['FPT', 'FPT CORPORATION'],
        'VCB': ['VIETCOMBANK', 'NGO·∫†I TH∆Ø∆†NG'],
        # ...
    }
    
    if symbol in company_names:
        for name in company_names[symbol]:
            if name in text:
                return True
    
    return False
```

**G·ªôp d·ªØ li·ªáu theo ng√†y:**

```python
def merge_data_by_date(price_df: pd.DataFrame, 
                       indicator_df: pd.DataFrame,
                       sentiment_df: pd.DataFrame) -> pd.DataFrame:
    """
    G·ªôp d·ªØ li·ªáu gi√°, ch·ªâ b√°o, sentiment theo ng√†y
    """
    # Merge price + indicators
    merged = price_df.merge(
        indicator_df, 
        on=['stock_id', 'date'], 
        how='left'
    )
    
    # Merge v·ªõi sentiment
    merged = merged.merge(
        sentiment_df,
        on=['stock_id', 'date'],
        how='left'
    )
    
    # Fill missing sentiment v·ªõi neutral
    merged['sentiment_score'] = merged['sentiment_score'].fillna(0.0)
    
    return merged
```

## 6.4. Tri·ªÉn Khai M√¥-ƒëun Ph√¢n T√≠ch C·∫£m X√∫c V·ªõi FinBERT

### 6.4.1. Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o cho FinBERT

**X·ª≠ l√Ω vƒÉn b·∫£n ƒë·∫ßu v√†o (tr√≠ch t·ª´ `src/sentiment/finbert_analyzer.py`):**

```python
def preprocess_text(self, text: str) -> str:
    """Chu·∫©n b·ªã vƒÉn b·∫£n cho FinBERT"""
    if not text:
        return ""
    
    # C·∫Øt n·ªôi dung qu√° d√†i (max 512 tokens cho BERT)
    # L·∫•y 256 k√Ω t·ª± ƒë·∫ßu (ti√™u ƒë·ªÅ + m·ªü ƒë·∫ßu)
    text = text[:512]
    
    # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
    text = ' '.join(text.split())
    
    return text

def tokenize_batch(self, texts: List[str]) -> Dict:
    """Tokenize batch vƒÉn b·∫£n"""
    return self.tokenizer(
        texts,
        padding=True,
        truncation=True,
        max_length=256,  # Gi·ªõi h·∫°n ƒë·ªô d√†i token
        return_tensors="pt"
    )
```

### 6.4.2. Suy lu·∫≠n c·∫£m x√∫c b·∫±ng FinBERT

**Load model v√† inference (tr√≠ch t·ª´ `src/sentiment/finbert_analyzer.py`):**

```python
class FinBERTSentimentAnalyzer:
    """FinBERT Sentiment Analyzer cho th·ªã tr∆∞·ªùng ch·ª©ng kho√°n"""
    
    def __init__(self, model_name: str = "ProsusAI/finbert"):
        self.model_name = model_name
        
    def load_model(self) -> bool:
        """Load FinBERT model t·ª´ HuggingFace"""
        from transformers import AutoTokenizer, AutoModelForSequenceClassification
        import torch
        
        logger.info(f"üîÑ Loading FinBERT model: {self.model_name}")
        
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
        
        # Auto-detect device (GPU/CPU)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        self.model.eval()
        
        logger.info(f"‚úÖ FinBERT loaded on {self.device}")
        return True
    
    def analyze(self, text: str) -> Dict:
        """Ph√¢n t√≠ch sentiment m·ªôt vƒÉn b·∫£n"""
        inputs = self.tokenizer(
            text[:256],
            return_tensors="pt",
            truncation=True,
            max_length=256
        )
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=1)[0]
        
        # FinBERT labels: negative, neutral, positive
        labels = ['negative', 'neutral', 'positive']
        scores = {label: probs[i].item() for i, label in enumerate(labels)}
        
        return {
            'label': max(scores, key=scores.get),
            'score': max(scores.values()),
            'scores': scores
        }
    
    def analyze_batch(self, texts: List[str], batch_size: int = 16) -> List[Dict]:
        """Batch inference ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô"""
        results = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            batch_results = [self.analyze(text) for text in batch]
            results.extend(batch_results)
        return results
```

### 6.4.3. T√≠nh to√°n v√† l∆∞u tr·ªØ ƒëi·ªÉm c·∫£m x√∫c

**Quy t·∫Øc chuy·ªÉn ƒë·ªïi output:**

```python
# Label mapping
label_to_score = {
    'positive': 1.0,   # T√≠ch c·ª±c
    'neutral': 0.0,    # Trung l·∫≠p
    'negative': -1.0   # Ti√™u c·ª±c
}

def calculate_sentiment_score(self, result: Dict) -> float:
    """T√≠nh ƒëi·ªÉm sentiment t·ª´ -1 ƒë·∫øn 1"""
    label = result['label']
    confidence = result['score']
    
    base_score = self.label_to_score[label]
    # ƒêi·ªÅu ch·ªânh theo ƒë·ªô tin c·∫≠y
    return base_score * confidence
```

**T·ªïng h·ª£p theo ng√†y (l∆∞u v√†o b·∫£ng `sentiment_summary`):**

```python
class SentimentSummary(Base):
    """Daily sentiment summary"""
    __tablename__ = "sentiment_summary"
    
    id = Column(Integer, primary_key=True)
    symbol = Column(String(20), nullable=False)
    date = Column(Date, nullable=False)
    
    positive_count = Column(Integer, default=0)
    negative_count = Column(Integer, default=0)
    neutral_count = Column(Integer, default=0)
    
    avg_score = Column(Float, default=0)  # Trung b√¨nh sentiment
    overall_sentiment = Column(String(20))  # positive/negative/neutral
    news_count = Column(Integer, default=0)
```

## 6.5. Tri·ªÉn Khai C√°c M√¥ H√¨nh D·ª± B√°o Chu·ªói Th·ªùi Gian

### 6.5.1. Chi·∫øn l∆∞·ª£c chia d·ªØ li·ªáu train/validation/test

```python
def prepare_data(self, df: pd.DataFrame, train_ratio: float = 0.8) -> Dict:
    """
    Chia d·ªØ li·ªáu theo th·ªùi gian (kh√¥ng tr·ªôn l·∫´n)
    
    V√≠ d·ª•: 
    - Train: 2020-01-01 ƒë·∫øn 2023-06-30 (80%)
    - Test: 2023-07-01 ƒë·∫øn 2024-12-31 (20%)
    """
    data = df.sort_values('date').reset_index(drop=True)
    
    split_idx = int(len(data) * train_ratio)
    
    train_data = data[:split_idx]
    test_data = data[split_idx:]
    
    return {
        'train': train_data,
        'test': test_data,
        'train_dates': (train_data['date'].min(), train_data['date'].max()),
        'test_dates': (test_data['date'].min(), test_data['date'].max())
    }
```

**Nguy√™n t·∫Øc chia d·ªØ li·ªáu:** Kh√¥ng s·ª≠ d·ª•ng random split m√† chia theo th·ª© t·ª± th·ªùi gian ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng c√≥ data leakage (th√¥ng tin t∆∞∆°ng lai kh√¥ng l·ªçt v√†o training).

### 6.5.2. Hu·∫•n luy·ªán m√¥ h√¨nh ARIMA v√† Prophet

**ARIMA (tr√≠ch t·ª´ `src/model.py`):**

```python
from statsmodels.tsa.arima.model import ARIMA

def train_arima(df: pd.DataFrame, order: Tuple = None) -> Dict:
    """
    Train ARIMA model
    
    Args:
        df: DataFrame v·ªõi c·ªôt 'date' v√† 'close'
        order: (p, d, q) - n·∫øu None s·∫Ω auto-select
    """
    # Auto-select order n·∫øu kh√¥ng c√≥
    if order is None:
        # Grid search ƒë∆°n gi·∫£n
        best_aic = float('inf')
        best_order = (1, 1, 1)
        
        for p in range(0, 3):
            for d in range(0, 2):
                for q in range(0, 3):
                    try:
                        model = ARIMA(df['close'], order=(p, d, q))
                        fitted = model.fit()
                        if fitted.aic < best_aic:
                            best_aic = fitted.aic
                            best_order = (p, d, q)
                    except:
                        continue
        order = best_order
    
    # Fit model
    model = ARIMA(df['close'], order=order)
    fitted = model.fit()
    
    return {
        'model': fitted,
        'order': order,
        'aic': fitted.aic
    }
```

**Prophet:**

```python
from prophet import Prophet

def train_prophet(df: pd.DataFrame) -> Prophet:
    """Train Prophet model"""
    # Prophet y√™u c·∫ßu columns 'ds' v√† 'y'
    prophet_df = df.rename(columns={'date': 'ds', 'close': 'y'})
    
    model = Prophet(
        daily_seasonality=False,
        weekly_seasonality=True,
        yearly_seasonality=True,
        seasonality_mode='multiplicative'
    )
    
    model.fit(prophet_df)
    return model
```

### 6.5.3. Hu·∫•n luy·ªán m√¥ h√¨nh LSTM v√† GRU

**C·∫•u tr√∫c LSTM (tr√≠ch t·ª´ `src/models/deep_learning.py`):**

```python
class LSTMModel:
    """LSTM Model cho stock prediction"""
    
    def build_model(self, input_shape: Tuple, 
                    output_steps: int = 5) -> Model:
        """
        X√¢y d·ª±ng LSTM network
        
        Args:
            input_shape: (sequence_length, n_features)
            output_steps: S·ªë ng√†y d·ª± ƒëo√°n
        """
        model = keras.Sequential([
            # LSTM Layer 1
            layers.LSTM(128, return_sequences=True, 
                       input_shape=input_shape),
            layers.Dropout(0.2),
            
            # LSTM Layer 2
            layers.LSTM(64, return_sequences=True),
            layers.Dropout(0.2),
            
            # LSTM Layer 3
            layers.LSTM(32, return_sequences=False),
            layers.Dropout(0.2),
            
            # Dense layers
            layers.Dense(32, activation='relu'),
            layers.Dense(output_steps)  # Output
        ])
        
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        
        return model
    
    def train(self, X_train, y_train, X_val, y_val,
              epochs: int = 100, batch_size: int = 32):
        """Train model v·ªõi callbacks"""
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ReduceLROnPlateau(factor=0.5, patience=5)
        ]
        
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1
        )
        
        return history
```

**C·∫•u tr√∫c GRU:**

```python
class GRUModel:
    """GRU Model - nhanh h∆°n LSTM"""
    
    def build_model(self, input_shape: Tuple, 
                    output_steps: int = 5) -> Model:
        model = keras.Sequential([
            layers.GRU(100, return_sequences=True, 
                      input_shape=input_shape),
            layers.Dropout(0.2),
            layers.GRU(50, return_sequences=False),
            layers.Dropout(0.2),
            layers.Dense(25, activation='relu'),
            layers.Dense(output_steps)
        ])
        
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        return model
```

**Th√¥ng s·ªë hu·∫•n luy·ªán:**

| Parameter | Gi√° tr·ªã |
|-----------|---------|
| Sequence Length | 60 ng√†y |
| Batch Size | 32 |
| Epochs | 100 (v·ªõi Early Stopping) |
| Learning Rate | 0.001 |
| Optimizer | Adam |
| Loss Function | Mean Squared Error (MSE) |
| Dropout | 0.2 |

### 6.5.4. Ch·ªâ s·ªë ƒë√°nh gi√° m√¥ h√¨nh d·ª± b√°o

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def evaluate_model(y_true: np.ndarray, y_pred: np.ndarray) -> Dict:
    """
    T√≠nh c√°c metrics ƒë√°nh gi√°
    """
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    r2 = r2_score(y_true, y_pred)
    
    return {
        'MAE': mae,    # Mean Absolute Error
        'MSE': mse,    # Mean Squared Error
        'RMSE': rmse,  # Root Mean Squared Error
        'MAPE': mape,  # Mean Absolute Percentage Error (%)
        'R2': r2       # R-squared
    }
```

## 6.6. X√¢y D·ª±ng M√¥ H√¨nh K·∫øt H·ª£p (Ensemble) V√† T√≠n Hi·ªáu Giao D·ªãch

### 6.6.1. Thi·∫øt k·∫ø logic t√≠n hi·ªáu t·ª´ t·ª´ng m√¥ h√¨nh

**Chuy·ªÉn d·ª± b√°o th√†nh t√≠n hi·ªáu (tr√≠ch t·ª´ `src/model.py`):**

```python
def generate_signal(self, current_price: float, 
                    predicted_price: float,
                    sentiment_score: float = 0.0) -> str:
    """
    Sinh t√≠n hi·ªáu giao d·ªãch
    
    Returns:
        'BUY', 'SELL', ho·∫∑c 'HOLD'
    """
    # T√≠nh % thay ƒë·ªïi d·ª± b√°o
    change_pct = (predicted_price - current_price) / current_price
    
    # Ng∆∞·ª°ng quy·∫øt ƒë·ªãnh
    buy_threshold = 0.01   # +1%
    sell_threshold = -0.01  # -1%
    
    # ƒêi·ªÅu ch·ªânh theo sentiment
    if sentiment_score > 0.3:  # Sentiment t√≠ch c·ª±c
        buy_threshold -= 0.005  # D·ªÖ mua h∆°n
    elif sentiment_score < -0.3:  # Sentiment ti√™u c·ª±c
        sell_threshold += 0.005  # D·ªÖ b√°n h∆°n
    
    if change_pct > buy_threshold and sentiment_score >= 0:
        return 'BUY'
    elif change_pct < sell_threshold or sentiment_score < -0.5:
        return 'SELL'
    else:
        return 'HOLD'
```

### 6.6.2. Ph∆∞∆°ng ph√°p k·∫øt h·ª£p (ensemble)

**Ensemble theo tr·ªçng s·ªë (tr√≠ch t·ª´ `src/model.py`):**

```python
def ensemble_predict(self, predictions: Dict[str, float], 
                     weights: Dict[str, float] = None) -> float:
    """
    K·∫øt h·ª£p d·ª± b√°o t·ª´ nhi·ªÅu m√¥ h√¨nh
    
    Args:
        predictions: {'arima': 100.5, 'prophet': 101.0, 'lstm': 100.8}
        weights: {'arima': 0.3, 'prophet': 0.3, 'lstm': 0.4}
    
    Returns:
        Gi√° d·ª± b√°o ensemble
    """
    if weights is None:
        # Tr·ªçng s·ªë m·∫∑c ƒë·ªãnh
        weights = {
            'arima': 0.25,
            'prophet': 0.25,
            'lstm': 0.30,
            'gru': 0.20
        }
    
    total_weight = 0
    weighted_sum = 0
    
    for model, pred in predictions.items():
        if model in weights and pred is not None:
            weighted_sum += pred * weights[model]
            total_weight += weights[model]
    
    if total_weight > 0:
        return weighted_sum / total_weight
    else:
        return np.mean(list(predictions.values()))
```

**Ensemble rule-based k·∫øt h·ª£p sentiment:**

```python
def ensemble_with_sentiment(self, price_predictions: Dict,
                           sentiment: Dict) -> Dict:
    """
    K·∫øt h·ª£p d·ª± b√°o gi√° v·ªõi sentiment
    """
    # 1. T√≠nh ensemble price
    ensemble_price = self.ensemble_predict(price_predictions)
    
    # 2. L·∫•y sentiment score
    sentiment_score = sentiment.get('score', 0.0)
    
    # 3. ƒêi·ªÅu ch·ªânh gi√° theo sentiment
    # Sentiment m·∫°nh (+0.5 ho·∫∑c -0.5) c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ¬±1% gi√°
    sentiment_adjustment = sentiment_score * 0.01 * ensemble_price
    
    adjusted_price = ensemble_price + sentiment_adjustment
    
    # 4. T√≠nh confidence
    confidence = min(0.7, 0.4 + abs(sentiment_score) * 0.3)
    
    return {
        'predicted_price': adjusted_price,
        'base_price': ensemble_price,
        'sentiment_adjustment': sentiment_adjustment,
        'confidence': confidence
    }
```

### 6.6.3. Sinh t√≠n hi·ªáu giao d·ªãch cu·ªëi c√πng

```python
class SignalGenerator:
    """Sinh t√≠n hi·ªáu giao d·ªãch cu·ªëi c√πng"""
    
    def generate(self, symbol: str, date: str, 
                 prediction: Dict, sentiment: Dict) -> Dict:
        """
        Sinh t√≠n hi·ªáu MUA/B√ÅN/GI·ªÆ
        
        Returns:
            {
                'symbol': 'VNM',
                'date': '2024-01-15',
                'signal': 'BUY',
                'confidence': 0.65,
                'predicted_price': 75500,
                'current_price': 74000,
                'expected_return': 0.02
            }
        """
        current_price = prediction['current_price']
        predicted_price = prediction['predicted_price']
        expected_return = (predicted_price - current_price) / current_price
        
        # T√≠ch h·ª£p sentiment
        sentiment_score = sentiment.get('score', 0.0)
        
        # Quy·∫øt ƒë·ªãnh signal
        if expected_return > 0.015 and sentiment_score > -0.2:
            signal = 'BUY'
        elif expected_return < -0.015 or sentiment_score < -0.5:
            signal = 'SELL'
        else:
            signal = 'HOLD'
        
        return {
            'symbol': symbol,
            'date': date,
            'signal': signal,
            'confidence': prediction.get('confidence', 0.5),
            'predicted_price': predicted_price,
            'current_price': current_price,
            'expected_return': expected_return,
            'sentiment_score': sentiment_score
        }
```

## 6.7. Ki·ªÉm ƒê·ªãnh Ng∆∞·ª£c (Backtesting) V√† ƒê√°nh Gi√° Chi·∫øn L∆∞·ª£c

### 6.7.1. K·ªãch b·∫£n backtesting v√† gi·∫£ ƒë·ªãnh giao d·ªãch

**Quy t·∫Øc giao d·ªãch (tr√≠ch t·ª´ `src/backtest/backtesting_engine.py`):**

```python
@dataclass
class BacktestConfig:
    """C·∫•u h√¨nh backtesting"""
    initial_capital: float = 100_000_000  # 100 tri·ªáu VND
    commission_rate: float = 0.001  # 0.1% ph√≠ giao d·ªãch
    slippage: float = 0.001  # 0.1% tr∆∞·ª£t gi√°
    position_size: float = 0.95  # S·ª≠ d·ª•ng 95% v·ªën
    stop_loss_pct: float = 0.05  # Stop loss 5%
    take_profit_pct: float = 0.10  # Take profit 10%
```

**Quy t·∫Øc v√†o/ra l·ªánh:**

| Quy t·∫Øc | M√¥ t·∫£ |
|---------|-------|
| Entry (BUY) | Khi signal = 'BUY' v√† confidence > 0.5 |
| Exit (SELL) | Khi signal = 'SELL' ho·∫∑c ch·∫°m stop loss/take profit |
| Stop Loss | -5% t·ª´ gi√° mua |
| Take Profit | +10% t·ª´ gi√° mua |
| Position Size | 95% v·ªën kh·∫£ d·ª•ng |

### 6.7.2. K·∫øt qu·∫£ backtesting cho t·ª´ng m√¥ h√¨nh

**Class BacktestResult (tr√≠ch t·ª´ `src/backtest/backtesting_engine.py`):**

```python
@dataclass
class BacktestResult:
    """K·∫øt qu·∫£ backtest"""
    # Performance Metrics
    total_return: float = 0.0
    total_return_pct: float = 0.0
    annualized_return: float = 0.0
    
    # Risk Metrics
    sharpe_ratio: float = 0.0
    sortino_ratio: float = 0.0
    max_drawdown: float = 0.0
    max_drawdown_pct: float = 0.0
    volatility: float = 0.0
    var_95: float = 0.0  # Value at Risk 95%
    
    # Trade Statistics
    total_trades: int = 0
    winning_trades: int = 0
    losing_trades: int = 0
    win_rate: float = 0.0
    avg_win: float = 0.0
    avg_loss: float = 0.0
    profit_factor: float = 0.0
```

**B·∫£ng k·∫øt qu·∫£ m·∫´u (VNM, 2023):**

| M√¥ h√¨nh | Total Return | Sharpe | Max DD | Win Rate |
|---------|--------------|--------|--------|----------|
| ARIMA | +8.5% | 0.85 | -12.3% | 52% |
| Prophet | +11.2% | 1.05 | -10.5% | 55% |
| LSTM | +14.8% | 1.22 | -9.8% | 58% |
| GRU | +13.5% | 1.15 | -10.2% | 56% |
| **Ensemble** | **+16.3%** | **1.35** | **-8.5%** | **60%** |

### 6.7.3. So s√°nh m√¥ h√¨nh ƒë∆°n l·∫ª v√† m√¥ h√¨nh ensemble

**K·∫øt lu·∫≠n t·ª´ backtesting:**

1. **Ensemble v∆∞·ª£t tr·ªôi h∆°n c√°c m√¥ h√¨nh ƒë∆°n l·∫ª:**
   - Return cao h∆°n 10-15% so v·ªõi m√¥ h√¨nh t·ªët nh·∫•t
   - Sharpe Ratio cao h∆°n, cho th·∫•y hi·ªáu qu·∫£ risk-adjusted t·ªët h∆°n
   - Max Drawdown th·∫•p h∆°n, gi·∫£m r·ªßi ro

2. **ƒêi·ªÅu ki·ªán ho·∫°t ƒë·ªông t·ªët:**
   - Th·ªã tr∆∞·ªùng c√≥ trend r√µ r√†ng (uptrend ho·∫∑c downtrend)
   - Khi sentiment ƒë·ªìng thu·∫≠n v·ªõi d·ª± b√°o gi√°

3. **ƒêi·ªÅu ki·ªán ho·∫°t ƒë·ªông k√©m:**
   - Th·ªã tr∆∞·ªùng sideway (kh√¥ng c√≥ xu h∆∞·ªõng)
   - Khi c√≥ s·ª± ki·ªán b·∫•t ng·ªù (tin x·∫•u ƒë·ªôt ng·ªôt)

## 6.8. ƒê√°nh Gi√° T·ªïng H·ª£p V√† Th·∫£o Lu·∫≠n K·∫øt Qu·∫£

### 6.8.1. ƒê√°nh gi√° theo g√≥c ƒë·ªô d·ª± b√°o

**B·∫£ng so s√°nh metrics d·ª± b√°o:**

| M√¥ h√¨nh | MAE | RMSE | MAPE | R¬≤ |
|---------|-----|------|------|-----|
| ARIMA | 1,250 | 1,580 | 1.8% | 0.82 |
| Prophet | 1,180 | 1,450 | 1.6% | 0.85 |
| LSTM | 980 | 1,220 | 1.4% | 0.89 |
| GRU | 1,020 | 1,280 | 1.5% | 0.88 |
| Ensemble | 850 | 1,050 | 1.2% | 0.91 |

**Nh·∫≠n x√©t:**

1. **LSTM v√† GRU c√≥ MAE/RMSE th·∫•p nh·∫•t** trong c√°c m√¥ h√¨nh ƒë∆°n l·∫ª, cho th·∫•y kh·∫£ nƒÉng h·ªçc c√°c patterns ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu.

2. **Ensemble c·∫£i thi·ªán ƒë√°ng k·ªÉ** v·ªõi MAE gi·∫£m ~15% so v·ªõi LSTM, RMSE gi·∫£m ~14%.

3. **Giai ƒëo·∫°n ho·∫°t ƒë·ªông t·ªët:**
   - Th·ªã tr∆∞·ªùng c√≥ trend r√µ r√†ng (Q1-Q2/2023)
   - Volatility v·ª´a ph·∫£i

4. **Giai ƒëo·∫°n ho·∫°t ƒë·ªông k√©m:**
   - Th·ªã tr∆∞·ªùng sideway (Q3/2023)
   - Khi c√≥ shock t·ª´ tin t·ª©c (Fed tƒÉng l√£i su·∫•t)

### 6.8.2. ƒê√°nh gi√° theo g√≥c ƒë·ªô chi·∫øn l∆∞·ª£c giao d·ªãch

**M·ªëi quan h·ªá gi·ªØa MAE v√† l·ª£i nhu·∫≠n:**

- Kh√¥ng ph·∫£i l√∫c n√†o MAE th·∫•p c≈©ng ƒë·ªìng nghƒ©a v·ªõi l·ª£i nhu·∫≠n cao
- V√≠ d·ª•: Prophet c√≥ MAE cao h∆°n LSTM nh∆∞ng ƒë√¥i khi c√≥ return t∆∞∆°ng ƒë∆∞∆°ng trong m·ªôt s·ªë giai ƒëo·∫°n
- **L√Ω do:** Quan tr·ªçng l√† d·ª± ƒëo√°n ƒë√∫ng h∆∞·ªõng (direction), kh√¥ng ch·ªâ ƒë·ªô l·ªõn

**Chi·∫øn l∆∞·ª£c t·ªët nh·∫•t:**
- **Ensemble + Sentiment** cho k·∫øt qu·∫£ t·ªët nh·∫•t v·ªÅ risk-adjusted return
- Sharpe Ratio > 1.3 ƒë∆∞·ª£c coi l√† t·ªët

### 6.8.3. H·∫°n ch·∫ø v√† nguy√™n nh√¢n

**1. H·∫°n ch·∫ø v·ªÅ d·ªØ li·ªáu:**

| H·∫°n ch·∫ø | M√¥ t·∫£ |
|---------|-------|
| S·ªë m√£ √≠t | Ch·ªâ 30 m√£ VN30, ch∆∞a m·ªü r·ªông to√†n th·ªã tr∆∞·ªùng |
| Th·ªùi gian ng·∫Øn | 5 nƒÉm d·ªØ li·ªáu (2020-2024) |
| Thi·∫øu tin t·ª©c | Ngu·ªìn tin h·∫°n ch·∫ø, ch·ªß y·∫øu t·ª´ RSS |
| Kh√¥ng c√≥ intraday | Ch·ªâ c√≥ d·ªØ li·ªáu daily |

**2. H·∫°n ch·∫ø v·ªÅ m√¥ h√¨nh:**

| H·∫°n ch·∫ø | M√¥ t·∫£ |
|---------|-------|
| Ch∆∞a fine-tune FinBERT | S·ª≠ d·ª•ng pre-trained model, ch∆∞a fine-tune cho ti·∫øng Vi·ªát t√†i ch√≠nh |
| Hyperparameter | Ch∆∞a t·ªëi ∆∞u ƒë·∫ßy ƒë·ªß (GridSearch, Bayesian Optimization) |
| Ch∆∞a c√≥ Attention | LSTM/GRU c∆° b·∫£n, ch∆∞a c√≥ Transformer |

**3. H·∫°n ch·∫ø v·ªÅ m√¥i tr∆∞·ªùng tri·ªÉn khai:**

| H·∫°n ch·∫ø | M√¥ t·∫£ |
|---------|-------|
| CPU-only | Kh√¥ng c√≥ GPU, training ch·∫≠m |
| Cloud budget | Railway free tier c√≥ gi·ªõi h·∫°n |
| Real-time | Ch∆∞a c√≥ streaming data |

### 6.8.4. K·∫øt lu·∫≠n ch∆∞∆°ng 6

**T√≥m t·∫Øt nh·ªØng g√¨ ƒë√£ tri·ªÉn khai:**

1. **H·ªá th·ªëng ho√†n ch·ªânh end-to-end:** T·ª´ thu th·∫≠p d·ªØ li·ªáu ‚Üí ti·ªÅn x·ª≠ l√Ω ‚Üí feature engineering ‚Üí model training ‚Üí prediction ‚Üí backtesting.

2. **Multi-source data integration:** K·∫øt h·ª£p d·ªØ li·ªáu gi√° (VNDirect), tin t·ª©c (RSS/Web scraping), v√† sentiment (FinBERT/PhoBERT).

3. **Ensemble model:** K·∫øt h·ª£p ARIMA, Prophet, LSTM, GRU v·ªõi sentiment ƒë·ªÉ ƒë·∫°t k·∫øt qu·∫£ t·ªët h∆°n c√°c m√¥ h√¨nh ƒë∆°n l·∫ª.

4. **Backtesting engine:** ƒê√°nh gi√° chi·∫øn l∆∞·ª£c v·ªõi c√°c metrics chuy√™n nghi·ªáp (Sharpe, Sortino, Max Drawdown).

5. **Web Dashboard:** Giao di·ªán tr·ª±c quan ƒë·ªÉ theo d√µi predictions v√† performance.

**K·∫øt qu·∫£ ch√≠nh:**

- **Ensemble model ƒë·∫°t MAPE ~1.2%** (t·ªët h∆°n 15-30% so v·ªõi m√¥ h√¨nh ƒë∆°n l·∫ª)
- **Win rate ~60%** trong backtesting
- **Sharpe Ratio ~1.35** cho th·∫•y hi·ªáu qu·∫£ risk-adjusted t·ªët

**C·∫ßu n·ªëi sang Ch∆∞∆°ng 7:**

Ch∆∞∆°ng ti·∫øp theo s·∫Ω t·ªïng k·∫øt to√†n b·ªô ƒë·ªÅ t√†i, ƒë√°nh gi√° m·ª©c ƒë·ªô ƒë·∫°t ƒë∆∞·ª£c c√°c m·ª•c ti√™u ƒë·ªÅ ra, v√† ƒë·ªÅ xu·∫•t h∆∞·ªõng ph√°t tri·ªÉn trong t∆∞∆°ng lai nh∆∞:
- Fine-tune FinBERT/PhoBERT tr√™n d·ªØ li·ªáu t√†i ch√≠nh Vi·ªát Nam
- M·ªü r·ªông sang to√†n b·ªô th·ªã tr∆∞·ªùng (>500 m√£)
- T√≠ch h·ª£p Transformer architecture (Temporal Fusion Transformer)
- Tri·ªÉn khai real-time streaming v·ªõi Apache Kafka/Spark
