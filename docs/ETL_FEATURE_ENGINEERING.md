# ETL Pipeline & Feature Engineering

## ğŸ“Š Tá»•ng quan Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           DATA PIPELINE ARCHITECTURE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   EXTRACT    â”‚â”€â”€â”€â–¶â”‚  TRANSFORM   â”‚â”€â”€â”€â–¶â”‚     LOAD     â”‚â”€â”€â”€â–¶â”‚  FEATURE  â”‚ â”‚
â”‚  â”‚   (TrÃ­ch     â”‚    â”‚  (Biáº¿n Ä‘á»•i)  â”‚    â”‚   (Táº£i lÃªn)  â”‚    â”‚ ENGINEER  â”‚ â”‚
â”‚  â”‚    xuáº¥t)     â”‚    â”‚              â”‚    â”‚              â”‚    â”‚           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â”‚                   â”‚                   â”‚                   â”‚        â”‚
â”‚        â–¼                   â–¼                   â–¼                   â–¼        â”‚
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•—      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•—      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•—      â•”â•â•â•â•â•â•â•â•â•â•â•— â”‚
â”‚  â•‘ VNDirect   â•‘      â•‘ Validate   â•‘      â•‘ SQLite DB  â•‘      â•‘Technical â•‘ â”‚
â”‚  â•‘ API        â•‘      â•‘ Clean      â•‘      â•‘ CSV Files  â•‘      â•‘Indicatorsâ•‘ â”‚
â”‚  â•‘ Fireant    â•‘      â•‘ Normalize  â•‘      â•‘ Cloud S3   â•‘      â•‘FinBERT   â•‘ â”‚
â”‚  â•‘ Web Scrape â•‘      â•‘ Deduplicateâ•‘      â•‘            â•‘      â•‘Sentiment â•‘ â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•      â•šâ•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. EXTRACT - TrÃ­ch xuáº¥t dá»¯ liá»‡u

### 1.1 Module káº¿t ná»‘i API (VNDirect, Fireant)

**File:** `src/data_collection/vndirect_api.py`

```python
# Káº¿t ná»‘i VNDirect API láº¥y dá»¯ liá»‡u OHLCV
class VNDirectAPI:
    BASE_URL = "https://finfo-api.vndirect.com.vn"
    
    def get_stock_price(self, symbol: str, from_date: str, to_date: str) -> pd.DataFrame:
        """
        Láº¥y dá»¯ liá»‡u giÃ¡ lá»‹ch sá»­ tá»« VNDirect
        
        Returns:
            DataFrame vá»›i cÃ¡c cá»™t: date, Open, High, Low, Close, Volume
        """
```

**Endpoints Ä‘Æ°á»£c sá»­ dá»¥ng:**
| API | Endpoint | Má»¥c Ä‘Ã­ch |
|-----|----------|----------|
| VNDirect | `/v4/stock_prices` | Dá»¯ liá»‡u giÃ¡ OHLCV |
| VNDirect | `/v4/stocks` | ThÃ´ng tin cá»• phiáº¿u |
| VNDirect | `/v4/industry_classification` | PhÃ¢n ngÃ nh |

### 1.2 Web Scraping Module (BeautifulSoup)

**File:** `src/news_service.py`

```python
# Scraping tin tá»©c tá»« cÃ¡c nguá»“n
class NewsCollector:
    SOURCES = [
        "cafef.vn",
        "vnexpress.net/kinh-doanh",
        "fireant.vn"
    ]
    
    def scrape_news(self, symbol: str) -> List[Dict]:
        """
        QuÃ©t tin tá»©c liÃªn quan Ä‘áº¿n mÃ£ cá»• phiáº¿u
        
        Returns:
            List of {title, content, url, published_at, source}
        """
```

---

## 2. TRANSFORM - Biáº¿n Ä‘á»•i dá»¯ liá»‡u

### 2.1 Data Validation

**File:** `src/etl/etl_pipeline.py` - Class `DataValidator`

| Check | MÃ´ táº£ | NgÆ°á»¡ng |
|-------|-------|--------|
| Missing Values | % dá»¯ liá»‡u bá»‹ thiáº¿u | â‰¤ 5% |
| Duplicates | TrÃ¹ng láº·p theo date | 0 |
| OHLC Relationship | High â‰¥ Low, etc. | Valid |
| Price Range | GiÃ¡ trong khoáº£ng há»£p lá»‡ | 100 - 1,000,000 VND |
| Daily Change | Thay Ä‘á»•i giÃ¡ trong ngÃ y | â‰¤ 30% |
| Negative Values | GiÃ¡ Ã¢m khÃ´ng Ä‘Æ°á»£c phÃ©p | 0 |

### 2.2 Data Cleaning

**File:** `src/etl/etl_pipeline.py` - Class `DataTransformer`

```python
class DataTransformer:
    """Transform pipeline bao gá»“m:"""
    
    def standardize_columns(df):
        """Chuáº©n hÃ³a tÃªn cá»™t: DATEâ†’date, CLOSEâ†’Close, etc."""
    
    def clean_missing_values(df, method='ffill'):
        """Xá»­ lÃ½ missing: forward fill, interpolate, hoáº·c drop"""
    
    def remove_duplicates(df, keep='last'):
        """Loáº¡i bá» dá»¯ liá»‡u trÃ¹ng láº·p"""
    
    def fix_ohlc_relationship(df):
        """Sá»­a High/Low khÃ´ng há»£p lá»‡"""
    
    def convert_date(df):
        """Chuyá»ƒn Ä‘á»•i date sang datetime"""
```

### 2.3 Data Normalization

```python
# Chuáº©n hÃ³a giÃ¡ Ä‘á»ƒ training ML models
from sklearn.preprocessing import MinMaxScaler, StandardScaler

# MinMaxScaler cho LSTM/GRU
scaler = MinMaxScaler(feature_range=(0, 1))
normalized_prices = scaler.fit_transform(prices)

# StandardScaler cho cÃ¡c models khÃ¡c
standard_scaler = StandardScaler()
standardized_features = standard_scaler.fit_transform(features)
```

---

## 3. LOAD - Táº£i dá»¯ liá»‡u

### 3.1 Database Storage (SQLite)

**File:** `src/database/models.py`

```python
class StockPrice(Base):
    __tablename__ = 'stock_prices'
    
    id = Column(Integer, primary_key=True)
    symbol = Column(String, index=True)
    date = Column(Date, index=True)
    open = Column(Float)
    high = Column(Float)
    low = Column(Float)
    close = Column(Float)
    volume = Column(BigInteger)
    
    # Technical Indicators
    sma_20 = Column(Float)
    rsi = Column(Float)
    macd = Column(Float)
```

### 3.2 Raw Data Storage (CSV/Cloud)

```python
class CSVLoader(Loader):
    """LÆ°u dá»¯ liá»‡u thÃ´ vÃ o file CSV"""
    
    def load(self, df: pd.DataFrame, symbol: str) -> int:
        filename = f"./data/raw/{symbol}_{date}.csv"
        df.to_csv(filename, index=False)
```

**Cáº¥u trÃºc thÆ° má»¥c lÆ°u trá»¯:**
```
data/
â”œâ”€â”€ raw/                    # Dá»¯ liá»‡u thÃ´ chÆ°a xá»­ lÃ½
â”‚   â”œâ”€â”€ VNM_20241202.csv
â”‚   â”œâ”€â”€ VIC_20241202.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ processed/              # Dá»¯ liá»‡u Ä‘Ã£ transform
â”‚   â”œâ”€â”€ VNM_features.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                 # Saved models
â”‚   â”œâ”€â”€ lstm_VNM.h5
â”‚   â””â”€â”€ ...
â””â”€â”€ predictions/            # Káº¿t quáº£ dá»± Ä‘oÃ¡n
    â””â”€â”€ predictions_latest.json
```

---

## 4. FEATURE ENGINEERING - XÃ¢y dá»±ng Äáº·c trÆ°ng

### 4.1 Technical Indicators Module

**File:** `src/features/technical_indicators.py`

| Indicator | CÃ´ng thá»©c | Ã nghÄ©a |
|-----------|-----------|---------|
| **SMA** | $SMA_n = \frac{1}{n}\sum_{i=1}^{n} P_i$ | Xu hÆ°á»›ng trung bÃ¬nh |
| **EMA** | $EMA_t = \alpha \cdot P_t + (1-\alpha) \cdot EMA_{t-1}$ | Xu hÆ°á»›ng cÃ³ trá»ng sá»‘ |
| **RSI** | $RSI = 100 - \frac{100}{1 + RS}$ | QuÃ¡ mua/quÃ¡ bÃ¡n |
| **MACD** | $MACD = EMA_{12} - EMA_{26}$ | Äá»™ng lÆ°á»£ng |
| **Bollinger** | $BB = SMA \pm 2\sigma$ | Volatility bands |
| **ATR** | $ATR = \frac{1}{n}\sum TR$ | Biáº¿n Ä‘á»™ng |
| **Stochastic** | $\%K = \frac{C - L_{14}}{H_{14} - L_{14}} \times 100$ | Momentum |

**Code tÃ­nh toÃ¡n:**
```python
class TechnicalIndicators:
    def add_all_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """ThÃªm 20+ technical indicators vÃ o DataFrame"""
        
        # Moving Averages
        df['sma_5'] = df['close'].rolling(5).mean()
        df['sma_20'] = df['close'].rolling(20).mean()
        df['ema_12'] = df['close'].ewm(span=12).mean()
        
        # RSI (Relative Strength Index)
        delta = df['close'].diff()
        gain = delta.where(delta > 0, 0).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        df['rsi'] = 100 - (100 / (1 + gain/loss))
        
        # MACD
        df['macd'] = df['close'].ewm(span=12).mean() - df['close'].ewm(span=26).mean()
        df['macd_signal'] = df['macd'].ewm(span=9).mean()
        
        # Bollinger Bands
        df['bb_middle'] = df['close'].rolling(20).mean()
        df['bb_upper'] = df['bb_middle'] + 2 * df['close'].rolling(20).std()
        df['bb_lower'] = df['bb_middle'] - 2 * df['close'].rolling(20).std()
        
        return df
```

### 4.2 Sentiment Analysis Module (FinBERT)

**File:** `src/features/sentiment_analysis.py`

```python
class FinBERTSentimentAnalyzer:
    """
    PhÃ¢n tÃ­ch cáº£m tÃ­nh tin tá»©c tÃ i chÃ­nh sá»­ dá»¥ng FinBERT
    Model: ProsusAI/finbert (fine-tuned BERT cho financial domain)
    """
    
    def predict_sentiment(self, text: str) -> Dict:
        """
        Returns:
            {
                'positive': 0.85,   # XÃ¡c suáº¥t tÃ­ch cá»±c
                'negative': 0.05,   # XÃ¡c suáº¥t tiÃªu cá»±c
                'neutral': 0.10,    # XÃ¡c suáº¥t trung láº­p
                'sentiment': 'positive',
                'score': 0.85
            }
        """
```

**Aggregation theo ngÃ y:**
```python
class SentimentAggregator:
    def aggregate_by_date(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Tá»•ng há»£p sentiment score theo ngÃ y cho tá»«ng mÃ£ cá»• phiáº¿u
        
        Output columns:
        - daily_sentiment: (positive - negative) score
        - sentiment_ma_3: Moving average 3 ngÃ y
        - sentiment_ma_7: Moving average 7 ngÃ y
        - sentiment_momentum: Thay Ä‘á»•i sentiment
        - news_count: Sá»‘ tin tá»©c trong ngÃ y
        """
```

---

## 5. Complete ETL Pipeline

### 5.1 Full Pipeline Flow

```python
from src.etl.etl_pipeline import ETLPipeline, run_etl_for_symbol

# Khá»Ÿi táº¡o pipeline
pipeline = ETLPipeline(
    extractor=VNDirectExtractor(),
    loader=DatabaseLoader(db_session),
    validator=DataValidator(max_missing_pct=0.05),
    transformer=DataTransformer()
)

# Cháº¡y ETL cho má»™t mÃ£
result = pipeline.run(
    symbol='VNM',
    start_date='2024-01-01',
    end_date='2024-12-01',
    validate=True,
    add_features=True
)

print(result.to_dict())
# {
#     'success': True,
#     'symbol': 'VNM',
#     'records_extracted': 250,
#     'records_transformed': 248,
#     'records_loaded': 248,
#     'records_skipped': 2,
#     'duration_seconds': 3.45,
#     'validation': {
#         'is_valid': True,
#         'status': 'valid',
#         'stats': {'missing_pct': 0.5, 'duplicates': 0}
#     }
# }
```

### 5.2 Batch Processing

```python
# Cháº¡y ETL cho táº¥t cáº£ cá»• phiáº¿u
symbols = ['VNM', 'VIC', 'VHM', 'HPG', 'FPT', ...]

results = pipeline.run_batch(
    symbols=symbols,
    start_date='2024-01-01',
    end_date='2024-12-01'
)

# Summary
summary = pipeline.get_summary()
# {
#     'total_runs': 30,
#     'successful': 28,
#     'failed': 2,
#     'total_extracted': 7500,
#     'total_loaded': 7420,
#     'avg_duration_seconds': 2.8
# }
```

### 5.3 Incremental ETL (Daily Update)

```python
from src.etl.etl_pipeline import IncrementalETL

# Chá»‰ load dá»¯ liá»‡u má»›i tá»« ngÃ y cuá»‘i cÃ¹ng
incremental = IncrementalETL(pipeline, db_session)
result = incremental.run_incremental('VNM')

# Tá»± Ä‘á»™ng detect ngÃ y cuá»‘i cÃ¹ng trong DB vÃ  chá»‰ fetch dá»¯ liá»‡u má»›i
```

---

## 6. API Endpoints cho ETL

| Endpoint | Method | MÃ´ táº£ |
|----------|--------|-------|
| `/api/data/fetch/{symbol}` | POST | Fetch dá»¯ liá»‡u cho 1 mÃ£ |
| `/api/data/fetch-all` | POST | Fetch táº¥t cáº£ cá»• phiáº¿u |
| `/api/etl/run/{symbol}` | POST | Cháº¡y full ETL pipeline |
| `/api/etl/status` | GET | Xem tráº¡ng thÃ¡i ETL |
| `/api/features/{symbol}` | GET | Láº¥y features Ä‘Ã£ tÃ­nh |

---

## 7. Scheduled Jobs (Cron)

**File:** `src/scheduler/jobs.py`

```python
# Cháº¡y tá»± Ä‘á»™ng hÃ ng ngÃ y lÃºc 18:00 (sau giá» Ä‘Ã³ng cá»­a)
schedule.every().day.at("18:00").do(run_daily_etl)

# Cháº¡y má»—i tuáº§n Ä‘á»ƒ re-calculate indicators
schedule.every().monday.at("07:00").do(recalculate_features)

# Cháº¡y má»—i giá» Ä‘á»ƒ cáº­p nháº­t tin tá»©c
schedule.every().hour.do(fetch_latest_news)
```

---

## 8. Data Quality Metrics

| Metric | Má»¥c tiÃªu | Thá»±c táº¿ |
|--------|----------|---------|
| Missing Rate | < 5% | ~0.5% |
| Duplicate Rate | 0% | 0% |
| OHLC Validity | 100% | 99.8% |
| Data Freshness | T+1 | T+1 |
| API Success Rate | > 95% | 97.3% |

---

## 9. Files & Structure

```
src/
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ etl_pipeline.py          # Main ETL classes
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ technical_indicators.py  # MACD, RSI, BB, etc.
â”‚   â””â”€â”€ sentiment_analysis.py    # FinBERT sentiment
â”œâ”€â”€ data_collection/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ vndirect_api.py          # API connectors
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py                # SQLAlchemy models
â”‚   â””â”€â”€ connection.py            # DB connection
â””â”€â”€ scheduler/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ jobs.py                  # Scheduled tasks
```

---

## 10. Usage Examples

### Example 1: Full Pipeline

```python
# 1. Extract tá»« VNDirect
df_raw = extractor.extract('VNM', '2024-01-01', '2024-12-01')

# 2. Validate
validation = validator.validate(df_raw)
print(validation.to_dict())

# 3. Transform
df_clean = transformer.transform(df_raw, add_features=True)

# 4. Add Technical Indicators
ti = TechnicalIndicators()
df_features = ti.add_all_indicators(df_clean)

# 5. Load to Database
loader.load(df_features, 'VNM')
```

### Example 2: With Sentiment

```python
# 1. Collect news
news_df = news_collector.get_news('VNM')

# 2. Analyze sentiment
analyzer = FinBERTSentimentAnalyzer()
news_with_sentiment = analyzer.analyze_news_dataframe(news_df)

# 3. Aggregate by date
aggregator = SentimentAggregator()
daily_sentiment = aggregator.aggregate_by_date(news_with_sentiment)

# 4. Merge vá»›i price data
df_final = pd.merge(df_features, daily_sentiment, on=['date', 'symbol'])
```

---

*Document nÃ y mÃ´ táº£ Ä‘áº§y Ä‘á»§ ETL Pipeline vÃ  Feature Engineering modules trong dá»± Ã¡n KLTN Stock Prediction.*
