# ğŸ“Š ÄÃNH GIÃ MÃ” HÃŒNH MACHINE LEARNING

## Tá»•ng quan

TÃ i liá»‡u nÃ y trÃ¬nh bÃ y chi tiáº¿t vá» quÃ¡ trÃ¬nh Ä‘Ã¡nh giÃ¡ vÃ  so sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh Machine Learning Ä‘Æ°á»£c sá»­ dá»¥ng trong há»‡ thá»‘ng dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u.

---

## ğŸ“ˆ CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡

| # | MÃ´ hÃ¬nh | Loáº¡i | ThÆ° viá»‡n |
|---|---------|------|----------|
| 1 | ARIMA | Statistical Time Series | statsmodels |
| 2 | Prophet | Additive Time Series | prophet |
| 3 | LSTM | Deep Learning RNN | TensorFlow/Keras |
| 4 | GRU | Deep Learning RNN | TensorFlow/Keras |
| 5 | Ensemble | Combined Models | Custom |

---

## ğŸ“ CÃ¡c metrics Ä‘Ã¡nh giÃ¡

### 1. RMSE (Root Mean Square Error)
$$RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$

- **Ã nghÄ©a:** Äo sai sá»‘ trung bÃ¬nh bÃ¬nh phÆ°Æ¡ng
- **ÄÆ¡n vá»‹:** CÃ¹ng Ä‘Æ¡n vá»‹ vá»›i giÃ¡ (VND)
- **Má»¥c tiÃªu:** CÃ ng nhá» cÃ ng tá»‘t

### 2. MAE (Mean Absolute Error)
$$MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$$

- **Ã nghÄ©a:** Sai sá»‘ tuyá»‡t Ä‘á»‘i trung bÃ¬nh
- **ÄÆ¡n vá»‹:** CÃ¹ng Ä‘Æ¡n vá»‹ vá»›i giÃ¡ (VND)
- **Má»¥c tiÃªu:** CÃ ng nhá» cÃ ng tá»‘t

### 3. MAPE (Mean Absolute Percentage Error)
$$MAPE = \frac{100\%}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right|$$

- **Ã nghÄ©a:** Sai sá»‘ pháº§n trÄƒm trung bÃ¬nh
- **ÄÆ¡n vá»‹:** Pháº§n trÄƒm (%)
- **Má»¥c tiÃªu:** < 10% lÃ  tá»‘t

### 4. RÂ² Score (Coefficient of Determination)
$$R^2 = 1 - \frac{SS_{res}}{SS_{tot}} = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}$$

- **Ã nghÄ©a:** Tá»· lá»‡ variance Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi mÃ´ hÃ¬nh
- **Pháº¡m vi:** 0 Ä‘áº¿n 1 (1 lÃ  hoÃ n háº£o)
- **Má»¥c tiÃªu:** > 0.8 lÃ  tá»‘t

---

## ğŸ§ª PhÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡

### Train-Test Split
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Historical Data                      â”‚
â”‚                  (365 days of prices)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          Training Set           â”‚     Test Set        â”‚
â”‚           (80% data)            â”‚    (20% data)       â”‚
â”‚          292 trading days       â”‚   73 trading days   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Time Series Cross-Validation
```
Fold 1: [Train: D1-D200]  â†’ [Test: D201-D230]
Fold 2: [Train: D1-D230]  â†’ [Test: D231-D260]
Fold 3: [Train: D1-D260]  â†’ [Test: D261-D290]
Fold 4: [Train: D1-D290]  â†’ [Test: D291-D320]
Fold 5: [Train: D1-D320]  â†’ [Test: D321-D365]
```

---

## ğŸ“Š Káº¿t quáº£ Ä‘Ã¡nh giÃ¡

### Tá»•ng há»£p káº¿t quáº£ (Test Set - VNM)

| Model | RMSE | MAE | MAPE | RÂ² Score |
|-------|------|-----|------|----------|
| ARIMA | 3.45 | 2.89 | 3.12% | 0.86 |
| Prophet | 3.12 | 2.45 | 2.78% | 0.89 |
| LSTM | 2.34 | 1.89 | 2.15% | 0.94 |
| GRU | 2.51 | 2.02 | 2.28% | 0.92 |
| **Ensemble** | **2.12** | **1.68** | **1.94%** | **0.96** |

### Biá»ƒu Ä‘á»“ so sÃ¡nh

```
RMSE Comparison (Lower is better)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ARIMA     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 3.45
Prophet   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 3.12
LSTM      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 2.34
GRU       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 2.51
Ensemble  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 2.12 â˜… Best

RÂ² Score Comparison (Higher is better)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ARIMA     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.86
Prophet   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.89
LSTM      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.94
GRU       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.92
Ensemble  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.96 â˜… Best
```

---

## ğŸ” PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng mÃ´ hÃ¬nh

### 1. ARIMA (AutoRegressive Integrated Moving Average)

**Cáº¥u hÃ¬nh:**
```python
# Auto ARIMA parameters selection
from pmdarima import auto_arima

model = auto_arima(
    series,
    start_p=1, max_p=5,
    start_q=1, max_q=5,
    d=1, max_d=2,
    seasonal=False,
    trace=True,
    error_action='ignore',
    suppress_warnings=True,
    stepwise=True
)
# Best: ARIMA(5,1,2)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… ÄÆ¡n giáº£n, dá»… hiá»ƒu
- âœ… KhÃ´ng cáº§n nhiá»u dá»¯ liá»‡u
- âœ… Tá»‘t cho short-term prediction

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Giáº£ Ä‘á»‹nh linear relationships
- âŒ KhÃ´ng capture Ä‘Æ°á»£c non-linear patterns
- âŒ Nháº¡y cáº£m vá»›i outliers

**Káº¿t quáº£ theo symbol:**
| Symbol | RMSE | MAE | RÂ² |
|--------|------|-----|-----|
| VNM | 3.45 | 2.89 | 0.86 |
| FPT | 4.12 | 3.45 | 0.82 |
| VCB | 3.89 | 3.21 | 0.84 |
| HPG | 4.56 | 3.89 | 0.79 |

---

### 2. Prophet (Facebook)

**Cáº¥u hÃ¬nh:**
```python
from prophet import Prophet

model = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False,
    changepoint_prior_scale=0.05,
    seasonality_prior_scale=10,
    interval_width=0.95
)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Xá»­ lÃ½ tá»‘t missing values
- âœ… Tá»± Ä‘á»™ng phÃ¡t hiá»‡n seasonality
- âœ… Dá»… dÃ ng thÃªm holidays/events

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Cháº­m hÆ¡n ARIMA
- âŒ Cáº§n tuning nhiá»u hyperparameters
- âŒ KhÃ´ng phÃ¹ há»£p vá»›i volatile data

**Káº¿t quáº£ theo symbol:**
| Symbol | RMSE | MAE | RÂ² |
|--------|------|-----|-----|
| VNM | 3.12 | 2.45 | 0.89 |
| FPT | 3.78 | 3.01 | 0.85 |
| VCB | 3.45 | 2.89 | 0.87 |
| HPG | 4.23 | 3.56 | 0.81 |

---

### 3. LSTM (Long Short-Term Memory)

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Input Layer                       â”‚
â”‚                 (60, 1) - 60 timesteps              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LSTM Layer 1                       â”‚
â”‚               units=50, return_sequences=True       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Dropout Layer                      â”‚
â”‚                     rate=0.2                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LSTM Layer 2                       â”‚
â”‚               units=50, return_sequences=False      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Dropout Layer                      â”‚
â”‚                     rate=0.2                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Dense Layer                        â”‚
â”‚                    units=1                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Training configuration:**
```python
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='mse'
)

history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.1,
    callbacks=[EarlyStopping(patience=10)]
)
```

**Training curves:**
```
Epoch   Train Loss   Val Loss
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1       0.0234       0.0198
10      0.0089       0.0078
20      0.0045       0.0042
30      0.0028       0.0031
40      0.0021       0.0025
50      0.0018       0.0022
```

**Káº¿t quáº£ theo symbol:**
| Symbol | RMSE | MAE | RÂ² |
|--------|------|-----|-----|
| VNM | 2.34 | 1.89 | 0.94 |
| FPT | 2.89 | 2.34 | 0.91 |
| VCB | 2.67 | 2.12 | 0.92 |
| HPG | 3.12 | 2.56 | 0.88 |

---

### 4. GRU (Gated Recurrent Unit)

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Input Layer                       â”‚
â”‚                 (60, 1) - 60 timesteps              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GRU Layer 1                        â”‚
â”‚               units=50, return_sequences=True       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Dropout Layer                      â”‚
â”‚                     rate=0.2                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GRU Layer 2                        â”‚
â”‚               units=50, return_sequences=False      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Dense Layer                        â”‚
â”‚                    units=1                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**So sÃ¡nh LSTM vs GRU:**
| Aspect | LSTM | GRU |
|--------|------|-----|
| Parameters | 4 gates | 3 gates |
| Training time | Slower | Faster |
| Memory usage | Higher | Lower |
| Performance | Slightly better | Similar |

---

### 5. Ensemble Model

**PhÆ°Æ¡ng phÃ¡p káº¿t há»£p:**

#### Weighted Average
```python
# Weights based on inverse RMSE
weights = {
    'arima': 1/rmse_arima,
    'prophet': 1/rmse_prophet,
    'lstm': 1/rmse_lstm,
    'gru': 1/rmse_gru
}

# Normalize weights
total = sum(weights.values())
weights = {k: v/total for k, v in weights.items()}

# Final prediction
ensemble_pred = (
    weights['arima'] * arima_pred +
    weights['prophet'] * prophet_pred +
    weights['lstm'] * lstm_pred +
    weights['gru'] * gru_pred
)
```

**Calculated weights (VNM):**
| Model | RMSE | Weight |
|-------|------|--------|
| ARIMA | 3.45 | 0.18 |
| Prophet | 3.12 | 0.20 |
| LSTM | 2.34 | 0.32 |
| GRU | 2.51 | 0.30 |

#### Stacking Meta-Learner
```python
# Meta-features: predictions from base models
meta_features = np.column_stack([
    arima_predictions,
    prophet_predictions,
    lstm_predictions,
    gru_predictions
])

# Meta-learner: Ridge Regression
from sklearn.linear_model import Ridge
meta_model = Ridge(alpha=1.0)
meta_model.fit(meta_features, y_true)
```

---

## ğŸ“‰ Backtesting Results

### Chiáº¿n lÆ°á»£c Ä‘Ã¡nh giÃ¡

| Strategy | Description |
|----------|-------------|
| Buy & Hold | Mua vÃ  giá»¯ suá»‘t ká»³ |
| SMA Crossover | Mua khi SMA10 > SMA30, bÃ¡n ngÆ°á»£c láº¡i |
| ML Ensemble | Mua khi dá»± Ä‘oÃ¡n tÄƒng > 1%, bÃ¡n khi giáº£m > 1% |

### Káº¿t quáº£ (01/2024 - 11/2024)

| Metric | Buy & Hold | SMA Crossover | ML Ensemble |
|--------|------------|---------------|-------------|
| Total Return | 15.2% | 18.7% | 24.5% |
| Sharpe Ratio | 0.85 | 1.12 | 1.45 |
| Sortino Ratio | 1.02 | 1.35 | 1.78 |
| Max Drawdown | -15.2% | -10.5% | -8.3% |
| Win Rate | - | 58% | 62% |
| Profit Factor | - | 1.45 | 1.82 |
| Number of Trades | 1 | 45 | 38 |

### Equity Curve

```
Portfolio Value Over Time (Initial: 100,000,000 VND)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

125M â”¤                                              â•­â”€â”€â”€ ML Ensemble
     â”‚                                           â•­â”€â”€â•¯
     â”‚                                        â•­â”€â”€â•¯
120M â”¤                                     â•­â”€â”€â•¯
     â”‚                                  â•­â”€â”€â•¯     â•­â”€â”€â”€ SMA Crossover
     â”‚                               â•­â”€â”€â•¯     â•­â”€â”€â•¯
115M â”¤                            â•­â”€â”€â•¯     â•­â”€â”€â•¯
     â”‚                         â•­â”€â”€â•¯     â•­â”€â”€â•¯
     â”‚                      â•­â”€â”€â•¯     â•­â”€â”€â•¯        â•­â”€â”€â”€ Buy & Hold
110M â”¤                   â•­â”€â”€â•¯     â•­â”€â”€â•¯        â•­â”€â”€â•¯
     â”‚                â•­â”€â”€â•¯     â•­â”€â”€â•¯        â•­â”€â”€â•¯
     â”‚             â•­â”€â”€â•¯     â•­â”€â”€â•¯        â•­â”€â”€â•¯
105M â”¤          â•­â”€â”€â•¯     â•­â”€â”€â•¯        â•­â”€â”€â•¯
     â”‚       â•­â”€â”€â•¯     â•­â”€â”€â•¯        â•­â”€â”€â•¯
     â”‚    â•­â”€â”€â•¯     â•­â”€â”€â•¯        â•­â”€â”€â•¯
100M â”¼â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     Jan    Feb    Mar    Apr    May    Jun    Jul    Aug    Sep
```

---

## ğŸ”¬ Statistical Significance Tests

### Diebold-Mariano Test
So sÃ¡nh kháº£ nÄƒng dá»± Ä‘oÃ¡n giá»¯a cÃ¡c mÃ´ hÃ¬nh:

| Comparison | DM Statistic | p-value | Significant? |
|------------|--------------|---------|--------------|
| LSTM vs ARIMA | -2.34 | 0.019 | âœ… Yes |
| LSTM vs Prophet | -1.89 | 0.058 | âŒ No |
| Ensemble vs LSTM | -2.12 | 0.034 | âœ… Yes |
| GRU vs LSTM | 0.45 | 0.653 | âŒ No |

### Interpretation
- LSTM cÃ³ hiá»‡u suáº¥t tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i ARIMA (p < 0.05)
- Ensemble cÃ³ hiá»‡u suáº¥t tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i LSTM Ä‘Æ¡n láº»
- KhÃ´ng cÃ³ sá»± khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ giá»¯a LSTM vÃ  GRU

---

## ğŸ¯ Káº¿t luáº­n

### Model Recommendations

| Use Case | Recommended Model | Reason |
|----------|-------------------|--------|
| Quick prediction | ARIMA | Fastest, simple |
| Trend analysis | Prophet | Good seasonality handling |
| High accuracy | Ensemble | Best overall performance |
| Low latency | GRU | Fast inference, good accuracy |

### Future Improvements

1. **ThÃªm features:**
   - Sentiment scores tá»« FinBERT
   - Technical indicators (RSI, MACD)
   - Market indices (VN-Index)

2. **Cáº£i thiá»‡n models:**
   - Transformer-based models
   - Attention mechanisms
   - Hyperparameter optimization (Optuna)

3. **Ensemble improvements:**
   - Dynamic weight adjustment
   - Model uncertainty estimation
   - Online learning

---

## ğŸ“š References

1. [LSTM Networks](https://www.bioinf.jku.at/publications/older/2604.pdf) - Hochreiter & Schmidhuber, 1997
2. [Prophet](https://peerj.com/preprints/3190/) - Taylor & Letham, 2017
3. [ARIMA Models](https://www.jstor.org/stable/2286995) - Box & Jenkins, 1976
4. [GRU Networks](https://arxiv.org/abs/1406.1078) - Cho et al., 2014
