"""
News Service - Thu th·∫≠p v√† ph√¢n t√≠ch tin t·ª©c ch·ª©ng kho√°n
S·ª≠ d·ª•ng Sentiment Analysis ƒë·ªÉ d·ª± ƒëo√°n ·∫£nh h∆∞·ªüng ƒë·∫øn gi√° c·ªï phi·∫øu
"""

import re
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from dataclasses import dataclass
from enum import Enum


class SentimentType(str, Enum):
    POSITIVE = "positive"      # T√≠ch c·ª±c - c√≥ th·ªÉ tƒÉng gi√°
    NEGATIVE = "negative"      # Ti√™u c·ª±c - c√≥ th·ªÉ gi·∫£m gi√°
    NEUTRAL = "neutral"        # Trung l·∫≠p


@dataclass
class NewsArticle:
    title: str
    summary: str
    url: str
    source: str
    published_at: str
    symbol: Optional[str] = None
    sentiment: SentimentType = SentimentType.NEUTRAL
    sentiment_score: float = 0.0  # -1 ƒë·∫øn 1
    impact_prediction: str = ""   # D·ª± ƒëo√°n ·∫£nh h∆∞·ªüng


class SentimentAnalyzer:
    """
    Ph√¢n t√≠ch sentiment tin t·ª©c ch·ª©ng kho√°n Vi·ªát Nam
    S·ª≠ d·ª•ng t·ª´ ƒëi·ªÉn t·ª´ kh√≥a v√† rules
    """
    
    # T·ª´ kh√≥a t√≠ch c·ª±c - c√≥ th·ªÉ l√†m tƒÉng gi√°
    POSITIVE_KEYWORDS = [
        # T√†i ch√≠nh
        "tƒÉng tr∆∞·ªüng", "l·ª£i nhu·∫≠n tƒÉng", "doanh thu tƒÉng", "v∆∞·ª£t k·∫ø ho·∫°ch",
        "c·ªï t·ª©c cao", "chia c·ªï t·ª©c", "tƒÉng v·ªën", "ph√°t h√†nh th√™m",
        "l√£i r√≤ng", "l√£i k·ª∑ l·ª•c", "tƒÉng m·∫°nh", "b·ª©t ph√°",
        "tri·ªÉn v·ªçng t·ªët", "khuy·∫øn ngh·ªã mua", "m·ª•c ti√™u tƒÉng",
        # Kinh doanh
        "m·ªü r·ªông", "ƒë·∫ßu t∆∞ m·ªõi", "h·ª£p t√°c", "k√Ω k·∫øt",
        "th√¢u t√≥m", "s√°p nh·∫≠p", "d·ª± √°n m·ªõi", "th·∫Øng th·∫ßu",
        "xu·∫•t kh·∫©u tƒÉng", "th·ªã ph·∫ßn tƒÉng", "kh√°ch h√†ng m·ªõi",
        # Th·ªã tr∆∞·ªùng
        "uptrend", "breakout", "v∆∞·ª£t ƒë·ªânh", "thanh kho·∫£n cao",
        "kh·ªëi ngo·∫°i mua r√≤ng", "d√≤ng ti·ªÅn v√†o", "tƒÉng tr·∫ßn",
        # ƒê√°nh gi√°
        "outperform", "overweight", "strong buy", "n√¢ng rating",
    ]
    
    # T·ª´ kh√≥a ti√™u c·ª±c - c√≥ th·ªÉ l√†m gi·∫£m gi√°
    NEGATIVE_KEYWORDS = [
        # T√†i ch√≠nh
        "thua l·ªó", "l·ªó r√≤ng", "gi·∫£m l·ª£i nhu·∫≠n", "doanh thu gi·∫£m",
        "n·ª£ x·∫•u", "n·ª£ tƒÉng", "ph√° s·∫£n", "gi·∫£i th·ªÉ",
        "c·∫Øt c·ªï t·ª©c", "kh√¥ng chia c·ªï t·ª©c", "h·ªßy ni√™m y·∫øt",
        "b·ªã ph·∫°t", "vi ph·∫°m", "gian l·∫≠n", "ƒëi·ªÅu tra",
        # Kinh doanh  
        "thu h·∫πp", "ƒë√≥ng c·ª≠a", "c·∫Øt gi·∫£m", "sa th·∫£i",
        "m·∫•t h·ª£p ƒë·ªìng", "ki·ªán t·ª•ng", "tranh ch·∫•p",
        "t·ªìn kho tƒÉng", "kh√°ch h√†ng r·ªùi b·ªè",
        # Th·ªã tr∆∞·ªùng
        "downtrend", "breakdown", "m·∫•t ƒë√°y", "thanh kho·∫£n th·∫•p",
        "kh·ªëi ngo·∫°i b√°n r√≤ng", "d√≤ng ti·ªÅn ra", "gi·∫£m s√†n",
        "b√°n th√°o", "c·∫Øt l·ªó", "panic sell",
        # ƒê√°nh gi√°
        "underperform", "underweight", "sell", "h·∫° rating",
        "c·∫£nh b√°o", "r·ªßi ro cao",
    ]
    
    # T·ª´ kh√≥a m·∫°nh (tƒÉng tr·ªçng s·ªë)
    STRONG_MODIFIERS = ["k·ª∑ l·ª•c", "ƒë·ªôt bi·∫øn", "l·ªãch s·ª≠", "ch∆∞a t·ª´ng c√≥", "m·∫°nh nh·∫•t", "l·ªõn nh·∫•t"]
    WEAK_MODIFIERS = ["nh·∫π", "nh·ªè", "t·∫°m th·ªùi", "ng·∫Øn h·∫°n"]
    
    def analyze(self, text: str) -> tuple[SentimentType, float, str]:
        """
        Ph√¢n t√≠ch sentiment c·ªßa vƒÉn b·∫£n
        Returns: (sentiment_type, score, impact_prediction)
        """
        text_lower = text.lower()
        
        # ƒê·∫øm t·ª´ kh√≥a
        pos_count = sum(1 for kw in self.POSITIVE_KEYWORDS if kw in text_lower)
        neg_count = sum(1 for kw in self.NEGATIVE_KEYWORDS if kw in text_lower)
        
        # ƒêi·ªÅu ch·ªânh theo modifier
        has_strong = any(m in text_lower for m in self.STRONG_MODIFIERS)
        has_weak = any(m in text_lower for m in self.WEAK_MODIFIERS)
        
        multiplier = 1.5 if has_strong else (0.5 if has_weak else 1.0)
        
        # T√≠nh ƒëi·ªÉm
        total = pos_count + neg_count
        if total == 0:
            return SentimentType.NEUTRAL, 0.0, "Kh√¥ng c√≥ t√≠n hi·ªáu r√µ r√†ng"
        
        score = ((pos_count - neg_count) / total) * multiplier
        score = max(-1.0, min(1.0, score))  # Clamp to [-1, 1]
        
        # X√°c ƒë·ªãnh sentiment
        if score > 0.2:
            sentiment = SentimentType.POSITIVE
            if score > 0.6:
                impact = "üöÄ T√≠n hi·ªáu TƒÇNG M·∫†NH - Khuy·∫øn ngh·ªã MUA"
            else:
                impact = "üìà T√≠n hi·ªáu TƒÇNG - C√≥ th·ªÉ c√¢n nh·∫Øc mua"
        elif score < -0.2:
            sentiment = SentimentType.NEGATIVE
            if score < -0.6:
                impact = "üîª T√≠n hi·ªáu GI·∫¢M M·∫†NH - Khuy·∫øn ngh·ªã B√ÅN"
            else:
                impact = "üìâ T√≠n hi·ªáu GI·∫¢M - C√¢n nh·∫Øc c·∫Øt l·ªó"
        else:
            sentiment = SentimentType.NEUTRAL
            impact = "‚û°Ô∏è Trung l·∫≠p - Theo d√µi th√™m"
        
        return sentiment, score, impact


class NewsService:
    """
    Service thu th·∫≠p tin t·ª©c t·ª´ nhi·ªÅu ngu·ªìn
    """
    
    def __init__(self):
        self.analyzer = SentimentAnalyzer()
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        # Mapping m√£ CK -> t·ª´ kh√≥a t√¨m ki·∫øm
        self.stock_keywords = {
            "VNM": ["vinamilk", "VNM", "s·ªØa vinamilk"],
            "VIC": ["vingroup", "VIC", "t·∫≠p ƒëo√†n vin"],
            "VHM": ["vinhomes", "VHM", "b·∫•t ƒë·ªông s·∫£n vin"],
            "VCB": ["vietcombank", "VCB", "ng√¢n h√†ng ngo·∫°i th∆∞∆°ng"],
            "BID": ["bidv", "BID", "ng√¢n h√†ng ƒë·∫ßu t∆∞"],
            "CTG": ["vietinbank", "CTG", "ng√¢n h√†ng c√¥ng th∆∞∆°ng"],
            "TCB": ["techcombank", "TCB"],
            "MBB": ["mb bank", "MBB", "qu√¢n ƒë·ªôi"],
            "HPG": ["h√≤a ph√°t", "HPG", "th√©p h√≤a ph√°t"],
            "MSN": ["masan", "MSN", "t·∫≠p ƒëo√†n masan"],
            "FPT": ["fpt", "FPT"],
            "MWG": ["th·∫ø gi·ªõi di ƒë·ªông", "MWG", "ƒëi·ªán m√°y xanh"],
            "VPB": ["vpbank", "VPB"],
            "GAS": ["pvgas", "GAS", "kh√≠ vi·ªát nam"],
            "SAB": ["sabeco", "SAB", "bia s√†i g√≤n"],
            "PLX": ["petrolimex", "PLX", "xƒÉng d·∫ßu"],
            "VJC": ["vietjet", "VJC"],
            "SSI": ["ssi", "SSI", "ch·ª©ng kho√°n ssi"],
            "VRE": ["vincom retail", "VRE"],
            "POW": ["pv power", "POW"],
        }
    
    def get_news_cafef(self, symbol: str = None, limit: int = 10) -> List[NewsArticle]:
        """Thu th·∫≠p tin t·ª´ CafeF"""
        news = []
        try:
            # CafeF RSS ho·∫∑c API
            if symbol:
                url = f"https://cafef.vn/du-lieu/Ajax/Search.aspx?keyword={symbol}&type=1"
            else:
                url = "https://cafef.vn/chung-khoan.chn"
            
            # Gi·∫£ l·∫≠p d·ªØ li·ªáu (th·ª±c t·∫ø c·∫ßn scrape ho·∫∑c d√πng API)
            sample_news = self._get_sample_news(symbol)
            for item in sample_news[:limit]:
                sentiment, score, impact = self.analyzer.analyze(item["title"] + " " + item["summary"])
                news.append(NewsArticle(
                    title=item["title"],
                    summary=item["summary"],
                    url=item["url"],
                    source="CafeF",
                    published_at=item["date"],
                    symbol=symbol,
                    sentiment=sentiment,
                    sentiment_score=score,
                    impact_prediction=impact
                ))
        except Exception as e:
            print(f"Error fetching CafeF: {e}")
        return news
    
    def get_news_vndirect(self, symbol: str = None, limit: int = 10) -> List[NewsArticle]:
        """Thu th·∫≠p tin t·ª´ VNDirect"""
        news = []
        try:
            if symbol:
                url = f"https://www.vndirect.com.vn/portal/tin-tuc/{symbol}.shtml"
            
            sample_news = self._get_sample_news(symbol, source="VNDirect")
            for item in sample_news[:limit]:
                sentiment, score, impact = self.analyzer.analyze(item["title"] + " " + item["summary"])
                news.append(NewsArticle(
                    title=item["title"],
                    summary=item["summary"],
                    url=item["url"],
                    source="VNDirect",
                    published_at=item["date"],
                    symbol=symbol,
                    sentiment=sentiment,
                    sentiment_score=score,
                    impact_prediction=impact
                ))
        except Exception as e:
            print(f"Error fetching VNDirect: {e}")
        return news
    
    def get_all_news(self, symbol: str = None, limit: int = 20) -> List[NewsArticle]:
        """L·∫•y tin t·ª´ t·∫•t c·∫£ ngu·ªìn"""
        all_news = []
        all_news.extend(self.get_news_cafef(symbol, limit // 2))
        all_news.extend(self.get_news_vndirect(symbol, limit // 2))
        
        # S·∫Øp x·∫øp theo th·ªùi gian
        all_news.sort(key=lambda x: x.published_at, reverse=True)
        return all_news[:limit]
    
    def get_sentiment_summary(self, symbol: str) -> Dict:
        """T·ªïng h·ª£p sentiment cho m·ªôt m√£"""
        news = self.get_all_news(symbol, limit=20)
        
        if not news:
            return {
                "symbol": symbol,
                "total_news": 0,
                "sentiment": "neutral",
                "avg_score": 0,
                "positive": 0,
                "negative": 0,
                "neutral": 0,
                "recommendation": "Kh√¥ng c√≥ tin t·ª©c",
                "news": []
            }
        
        pos = sum(1 for n in news if n.sentiment == SentimentType.POSITIVE)
        neg = sum(1 for n in news if n.sentiment == SentimentType.NEGATIVE)
        neu = sum(1 for n in news if n.sentiment == SentimentType.NEUTRAL)
        avg_score = sum(n.sentiment_score for n in news) / len(news)
        
        # X√°c ƒë·ªãnh xu h∆∞·ªõng
        if avg_score > 0.3:
            overall = "positive"
            rec = "üü¢ XU H∆Ø·ªöNG T√çCH C·ª∞C - C√¢n nh·∫Øc MUA"
        elif avg_score < -0.3:
            overall = "negative"
            rec = "üî¥ XU H∆Ø·ªöNG TI√äU C·ª∞C - C√¢n nh·∫Øc B√ÅN"
        else:
            overall = "neutral"
            rec = "üü° TRUNG L·∫¨P - Ti·∫øp t·ª•c theo d√µi"
        
        return {
            "symbol": symbol,
            "total_news": len(news),
            "sentiment": overall,
            "avg_score": round(avg_score, 2),
            "positive": pos,
            "negative": neg,
            "neutral": neu,
            "recommendation": rec,
            "news": [
                {
                    "title": n.title,
                    "summary": n.summary,
                    "url": n.url,
                    "source": n.source,
                    "published_at": n.published_at,
                    "sentiment": n.sentiment.value,
                    "score": round(n.sentiment_score, 2),
                    "impact": n.impact_prediction
                }
                for n in news[:10]
            ]
        }
    
    def _get_sample_news(self, symbol: str = None, source: str = "CafeF") -> List[Dict]:
        """D·ªØ li·ªáu m·∫´u (th·ª±c t·∫ø s·∫Ω scrape t·ª´ web)"""
        today = datetime.now()
        
        # Tin chung th·ªã tr∆∞·ªùng
        general_news = [
            {
                "title": "VN-Index tƒÉng m·∫°nh, thanh kho·∫£n ƒë·∫°t k·ª∑ l·ª•c 25.000 t·ª∑ ƒë·ªìng",
                "summary": "Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n phi√™n h√¥m nay ch·ª©ng ki·∫øn ƒë√† tƒÉng m·∫°nh v·ªõi d√≤ng ti·ªÅn ƒë·ªï v√†o c√°c c·ªï phi·∫øu bluechip. Kh·ªëi ngo·∫°i mua r√≤ng h∆°n 500 t·ª∑ ƒë·ªìng.",
                "url": f"https://{source.lower()}.vn/news/1",
                "date": (today - timedelta(hours=2)).strftime("%Y-%m-%d %H:%M")
            },
            {
                "title": "Fed gi·ªØ nguy√™n l√£i su·∫•t, ch·ª©ng kho√°n ch√¢u √Å tƒÉng ƒëi·ªÉm",
                "summary": "Quy·∫øt ƒë·ªãnh gi·ªØ nguy√™n l√£i su·∫•t c·ªßa Fed t·∫°o t√¢m l√Ω t√≠ch c·ª±c cho th·ªã tr∆∞·ªùng ch√¢u √Å. Tri·ªÉn v·ªçng d√≤ng v·ªën ngo·∫°i v√†o Vi·ªát Nam ƒë∆∞·ª£c ƒë√°nh gi√° kh·∫£ quan.",
                "url": f"https://{source.lower()}.vn/news/2", 
                "date": (today - timedelta(hours=5)).strftime("%Y-%m-%d %H:%M")
            },
            {
                "title": "C·∫£nh b√°o r·ªßi ro margin, nhi·ªÅu nh√† ƒë·∫ßu t∆∞ b·ªã call margin",
                "summary": "Th·ªã tr∆∞·ªùng gi·∫£m s√¢u khi·∫øn nhi·ªÅu nh√† ƒë·∫ßu t∆∞ s·ª≠ d·ª•ng ƒë√≤n b·∫©y cao ph·∫£i b√°n th√°o c·ªï phi·∫øu. C√°c c√¥ng ty ch·ª©ng kho√°n si·∫øt ch·∫∑t t·ª∑ l·ªá margin.",
                "url": f"https://{source.lower()}.vn/news/3",
                "date": (today - timedelta(days=1)).strftime("%Y-%m-%d %H:%M")
            },
        ]
        
        # Tin theo m√£ c·ªï phi·∫øu
        stock_specific_news = {
            "VNM": [
                {
                    "title": "Vinamilk b√°o l√£i k·ª∑ l·ª•c qu√Ω 3, v∆∞·ª£t 15% k·∫ø ho·∫°ch nƒÉm",
                    "summary": "CTCP S·ªØa Vi·ªát Nam (VNM) c√¥ng b·ªë l·ª£i nhu·∫≠n sau thu·∫ø qu√Ω 3 ƒë·∫°t 3.200 t·ª∑ ƒë·ªìng, tƒÉng tr∆∞·ªüng 18% so v·ªõi c√πng k·ª≥. Doanh thu xu·∫•t kh·∫©u tƒÉng m·∫°nh 25%.",
                    "url": f"https://{source.lower()}.vn/vnm/1",
                    "date": (today - timedelta(hours=3)).strftime("%Y-%m-%d %H:%M")
                },
                {
                    "title": "VNM s·∫Ω chia c·ªï t·ª©c ti·ªÅn m·∫∑t 20%, t·ª∑ l·ªá cao nh·∫•t ng√†nh",
                    "summary": "HƒêQT Vinamilk th√¥ng qua ph∆∞∆°ng √°n chia c·ªï t·ª©c nƒÉm 2025 b·∫±ng ti·ªÅn m·∫∑t v·ªõi t·ª∑ l·ªá 20%. Ng√†y ch·ªët quy·ªÅn d·ª± ki·∫øn 15/12.",
                    "url": f"https://{source.lower()}.vn/vnm/2",
                    "date": (today - timedelta(days=1)).strftime("%Y-%m-%d %H:%M")
                },
            ],
            "VIC": [
                {
                    "title": "Vingroup ƒë·∫©y m·∫°nh ƒë·∫ßu t∆∞ c√¥ng ngh·ªá, r√≥t th√™m 500 tri·ªáu USD cho VinFast",
                    "summary": "T·∫≠p ƒëo√†n Vingroup c√¥ng b·ªë k·∫ø ho·∫°ch tƒÉng v·ªën ƒë·∫ßu t∆∞ cho VinFast nh·∫±m m·ªü r·ªông th·ªã tr∆∞·ªùng xe ƒëi·ªán t·∫°i M·ªπ v√† ch√¢u √Çu.",
                    "url": f"https://{source.lower()}.vn/vic/1",
                    "date": (today - timedelta(hours=4)).strftime("%Y-%m-%d %H:%M")
                },
            ],
            "HPG": [
                {
                    "title": "H√≤a Ph√°t: Gi√° th√©p ph·ª•c h·ªìi, l·ª£i nhu·∫≠n Q4 d·ª± ki·∫øn tƒÉng 30%",
                    "summary": "Gi√° th√©p trong n∆∞·ªõc v√† xu·∫•t kh·∫©u tƒÉng m·∫°nh gi√∫p bi√™n l·ª£i nhu·∫≠n c·ªßa H√≤a Ph√°t c·∫£i thi·ªán ƒë√°ng k·ªÉ. C√°c CTCK n√¢ng khuy·∫øn ngh·ªã t·ª´ Hold l√™n Buy.",
                    "url": f"https://{source.lower()}.vn/hpg/1",
                    "date": (today - timedelta(hours=6)).strftime("%Y-%m-%d %H:%M")
                },
                {
                    "title": "HPG b·ªã ƒëi·ªÅu tra b√°n ph√° gi√° t·∫°i th·ªã tr∆∞·ªùng EU",
                    "summary": "·ª¶y ban Ch√¢u √Çu kh·ªüi x∆∞·ªõng ƒëi·ªÅu tra ch·ªëng b√°n ph√° gi√° ƒë·ªëi v·ªõi th√©p cu·ªôn c√°n n√≥ng t·ª´ Vi·ªát Nam, trong ƒë√≥ c√≥ s·∫£n ph·∫©m c·ªßa H√≤a Ph√°t.",
                    "url": f"https://{source.lower()}.vn/hpg/2",
                    "date": (today - timedelta(days=2)).strftime("%Y-%m-%d %H:%M")
                },
            ],
            "VCB": [
                {
                    "title": "Vietcombank l√£i k·ª∑ l·ª•c h∆°n 40.000 t·ª∑ ƒë·ªìng nƒÉm 2025",
                    "summary": "Ng√¢n h√†ng TMCP Ngo·∫°i th∆∞∆°ng Vi·ªát Nam d·ª± ki·∫øn ƒë·∫°t l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø h∆°n 40.000 t·ª∑ ƒë·ªìng, tƒÉng 15% so v·ªõi nƒÉm tr∆∞·ªõc v√† l√† m·ª©c cao nh·∫•t ng√†nh.",
                    "url": f"https://{source.lower()}.vn/vcb/1",
                    "date": (today - timedelta(hours=8)).strftime("%Y-%m-%d %H:%M")
                },
            ],
            "FPT": [
                {
                    "title": "FPT k√Ω h·ª£p ƒë·ªìng AI tr·ªã gi√° 200 tri·ªáu USD v·ªõi ƒë·ªëi t√°c Nh·∫≠t B·∫£n",
                    "summary": "T·∫≠p ƒëo√†n FPT c√¥ng b·ªë k√Ω k·∫øt th·ªèa thu·∫≠n h·ª£p t√°c chi·∫øn l∆∞·ª£c v·ªÅ tr√≠ tu·ªá nh√¢n t·∫°o v·ªõi t·∫≠p ƒëo√†n c√¥ng ngh·ªá h√†ng ƒë·∫ßu Nh·∫≠t B·∫£n, tr·ªã gi√° 200 tri·ªáu USD trong 5 nƒÉm.",
                    "url": f"https://{source.lower()}.vn/fpt/1",
                    "date": (today - timedelta(hours=1)).strftime("%Y-%m-%d %H:%M")
                },
            ],
            "MWG": [
                {
                    "title": "Th·∫ø Gi·ªõi Di ƒê·ªông ƒë√≥ng c·ª≠a th√™m 100 c·ª≠a h√†ng, t√°i c∆° c·∫•u m·∫°nh",
                    "summary": "MWG th√¥ng b√°o ƒë√≥ng c·ª≠a th√™m 100 c·ª≠a h√†ng ƒëi·ªán m√°y kh√¥ng hi·ªáu qu·∫£ trong Q4/2025. C√¥ng ty t·∫≠p trung v√†o m·∫£ng B√°ch H√≥a Xanh v√† online.",
                    "url": f"https://{source.lower()}.vn/mwg/1",
                    "date": (today - timedelta(days=1)).strftime("%Y-%m-%d %H:%M")
                },
            ],
        }
        
        result = general_news.copy()
        
        if symbol and symbol.upper() in stock_specific_news:
            result = stock_specific_news[symbol.upper()] + result
        
        return result


# Singleton instance
news_service = NewsService()
